{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #004B87; padding: 20px; text-align: center; border-radius: 10px; color: white; font-family: Arial, sans-serif; margin: auto; width: 80%;\">\n",
        "    <h1>Module 3 Assignment</h1>\n",
        "    <h2>RURANGWA IRADUKUNDA Jean-François Régis</h2>\n",
        "    <h3>September 7, 2025</h3>\n",
        "    <p>Email : jeanfrancoisregis.rurangwairadukunda@axa.be</p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "xcKz6uU8Ce7X"
      },
      "id": "xcKz6uU8Ce7X"
    },
    {
      "cell_type": "markdown",
      "id": "516ee1d7-d4a0-4378-9a73-ff977fe061e6",
      "metadata": {
        "id": "516ee1d7-d4a0-4378-9a73-ff977fe061e6"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "Following the 'Actuarial Data Scientist' program offered by the Belgian association of actuaries (IABE), we are assessed an assignment that builds on the foundational concepts learned in the third and last module.\n",
        "<br/>\n",
        "This assignment involves analyzing the \"eusavingULnoPS\" dataset which is based on unit-linked saving products, with no profit sharing, sold in an unknown European country. Those insurance policies are observed between 1999 and 2008, with entries and exits possible.\n",
        "<br/>\n",
        "\n",
        "In this analysis, we will focus on developing classification and regression models for specific targets, applying feature selection techniques, and implementing explainability and fairness assessments.\n",
        "<br/>\n",
        "The objective is to provide actionable insights into the factors influencing policy lapses and risk premium proportions, ensuring the models are transparent, fair, and robust."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EUzqdV0xOgZZ",
      "metadata": {
        "id": "EUzqdV0xOgZZ"
      },
      "source": [
        "## Importing packages <a name=\"Importing_packages\"></a>\n",
        "\n",
        "Our first step is to import and load the packages that will be necessary in our task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YuP6mnV0_mJi",
      "metadata": {
        "id": "YuP6mnV0_mJi",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "## Perform these pip installs in the command prompt, with your python kernel activated\n",
        "!pip install shap\n",
        "!pip install tensorflow\n",
        "!pip install shapicant\n",
        "!pip install scikeras\n",
        "!pip install mlflow\n",
        "!pip install evidently\n",
        "!pip install boruta\n",
        "!pip install pandas scikit-learn deap\n",
        "!pip install aif360\n",
        "\n",
        "!git clone https://github.com/Regis0323/Module-3-assignment.git\n",
        "!pip install scikit-fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9b658fa8-eb1f-42b4-8178-42687d0f6f95",
      "metadata": {
        "id": "9b658fa8-eb1f-42b4-8178-42687d0f6f95",
        "tags": [],
        "collapsed": true,
        "outputId": "69ec253f-b6d8-4627-e307-996a0ec55587",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n",
            "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n",
            "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
            "pip install 'aif360[inFairness]'\n",
            "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n"
          ]
        }
      ],
      "source": [
        "# 1. SETUP: load libraries & data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data preprocesing and models\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.linear_model import LassoCV, Lasso\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# MLFlow\n",
        "import mlflow\n",
        "import cloudpickle\n",
        "from evidently import Dataset\n",
        "from evidently import DataDefinition\n",
        "from evidently import Report\n",
        "from evidently.presets import DataDriftPreset, DataSummaryPreset\n",
        "\n",
        "# Feature selection and explainability of the model\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.inspection import permutation_importance\n",
        "from boruta import BorutaPy\n",
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "\n",
        "# Bias mitigation\n",
        "from aif360.datasets import StandardDataset, BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
        "from aif360.algorithms.preprocessing import Reweighing, OptimPreproc\n",
        "from aif360.algorithms.inprocessing import MetaFairClassifier, AdversarialDebiasing\n",
        "from aif360.algorithms.postprocessing import RejectOptionClassification, EqOddsPostprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2W8hGUD_Pb7q",
      "metadata": {
        "id": "2W8hGUD_Pb7q"
      },
      "source": [
        "# Data exploration and preoprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we load the dataset and get its specificities."
      ],
      "metadata": {
        "id": "Fix3fVKMTmvF"
      },
      "id": "Fix3fVKMTmvF"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3f6e45e6-3c45-4ceb-8db7-130c4a5f9d2d",
      "metadata": {
        "id": "3f6e45e6-3c45-4ceb-8db7-130c4a5f9d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "44b2cc9a-616a-4169-8f68-29b5abd1b68c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  policy.ID  issue.date termination.date lapse.reason premium.frequency  \\\n",
              "0        N1  1999-01-01       2006-04-01        Claim            unique   \n",
              "1        N2  1999-01-01       2006-04-01        Claim            unique   \n",
              "2        N3  1999-01-01       2005-04-01    Surrender            unique   \n",
              "3        N4  1999-01-01       2003-02-01    Surrender            unique   \n",
              "4        N5  1999-01-01       2008-01-01     In force            unique   \n",
              "\n",
              "   gender  underwriting.age  face.amount  risk.premium  saving.premium  ...  \\\n",
              "0    Male                77      2979.53        265.86        29795.27  ...   \n",
              "1    Male                77      3039.71        271.23        30397.16  ...   \n",
              "2  Female                72      2994.12         80.43        35929.44  ...   \n",
              "3    Male                35      3051.10          7.50        30511.01  ...   \n",
              "4    Male                40      5810.21         81.39        58102.11  ...   \n",
              "\n",
              "   rate2Y.relvar1mth  rate2Y.relvar1qtr  rate10Y.relvar1mth  \\\n",
              "0           0.086310           0.184211            0.081598   \n",
              "1           0.086310           0.184211            0.081598   \n",
              "2          -0.025391          -0.018489           -0.023343   \n",
              "3          -0.041762          -0.133838           -0.038309   \n",
              "4           0.037712          -0.004430            0.025938   \n",
              "\n",
              "   rate10Y.relvar1qtr  unemploy.relvar1mth  unemploy.relvar1qtr  \\\n",
              "0            0.144626            -0.011494            -0.011494   \n",
              "1            0.144626            -0.011494            -0.011494   \n",
              "2           -0.018868            -0.010309            -0.040816   \n",
              "3           -0.039273             0.000000            -0.008850   \n",
              "4           -0.002027             0.022727             0.069767   \n",
              "\n",
              "   industry.relvar1mth  industry.relvar1qtr  RTV.relvar1mth  RTV.relvar1qtr  \n",
              "0            -0.000979             0.016699        0.005941        0.006931  \n",
              "1            -0.000979             0.016699        0.005941        0.006931  \n",
              "2             0.001000             0.003024        0.002002        0.000998  \n",
              "3            -0.003067             0.000000        0.009524        0.009574  \n",
              "4             0.001876             0.000941       -0.011550       -0.026692  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a543bcf9-0801-4a81-9fb3-39c2d86f7c31\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>policy.ID</th>\n",
              "      <th>issue.date</th>\n",
              "      <th>termination.date</th>\n",
              "      <th>lapse.reason</th>\n",
              "      <th>premium.frequency</th>\n",
              "      <th>gender</th>\n",
              "      <th>underwriting.age</th>\n",
              "      <th>face.amount</th>\n",
              "      <th>risk.premium</th>\n",
              "      <th>saving.premium</th>\n",
              "      <th>...</th>\n",
              "      <th>rate2Y.relvar1mth</th>\n",
              "      <th>rate2Y.relvar1qtr</th>\n",
              "      <th>rate10Y.relvar1mth</th>\n",
              "      <th>rate10Y.relvar1qtr</th>\n",
              "      <th>unemploy.relvar1mth</th>\n",
              "      <th>unemploy.relvar1qtr</th>\n",
              "      <th>industry.relvar1mth</th>\n",
              "      <th>industry.relvar1qtr</th>\n",
              "      <th>RTV.relvar1mth</th>\n",
              "      <th>RTV.relvar1qtr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N1</td>\n",
              "      <td>1999-01-01</td>\n",
              "      <td>2006-04-01</td>\n",
              "      <td>Claim</td>\n",
              "      <td>unique</td>\n",
              "      <td>Male</td>\n",
              "      <td>77</td>\n",
              "      <td>2979.53</td>\n",
              "      <td>265.86</td>\n",
              "      <td>29795.27</td>\n",
              "      <td>...</td>\n",
              "      <td>0.086310</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>0.081598</td>\n",
              "      <td>0.144626</td>\n",
              "      <td>-0.011494</td>\n",
              "      <td>-0.011494</td>\n",
              "      <td>-0.000979</td>\n",
              "      <td>0.016699</td>\n",
              "      <td>0.005941</td>\n",
              "      <td>0.006931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N2</td>\n",
              "      <td>1999-01-01</td>\n",
              "      <td>2006-04-01</td>\n",
              "      <td>Claim</td>\n",
              "      <td>unique</td>\n",
              "      <td>Male</td>\n",
              "      <td>77</td>\n",
              "      <td>3039.71</td>\n",
              "      <td>271.23</td>\n",
              "      <td>30397.16</td>\n",
              "      <td>...</td>\n",
              "      <td>0.086310</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>0.081598</td>\n",
              "      <td>0.144626</td>\n",
              "      <td>-0.011494</td>\n",
              "      <td>-0.011494</td>\n",
              "      <td>-0.000979</td>\n",
              "      <td>0.016699</td>\n",
              "      <td>0.005941</td>\n",
              "      <td>0.006931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N3</td>\n",
              "      <td>1999-01-01</td>\n",
              "      <td>2005-04-01</td>\n",
              "      <td>Surrender</td>\n",
              "      <td>unique</td>\n",
              "      <td>Female</td>\n",
              "      <td>72</td>\n",
              "      <td>2994.12</td>\n",
              "      <td>80.43</td>\n",
              "      <td>35929.44</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.025391</td>\n",
              "      <td>-0.018489</td>\n",
              "      <td>-0.023343</td>\n",
              "      <td>-0.018868</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>-0.040816</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.003024</td>\n",
              "      <td>0.002002</td>\n",
              "      <td>0.000998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N4</td>\n",
              "      <td>1999-01-01</td>\n",
              "      <td>2003-02-01</td>\n",
              "      <td>Surrender</td>\n",
              "      <td>unique</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>3051.10</td>\n",
              "      <td>7.50</td>\n",
              "      <td>30511.01</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.041762</td>\n",
              "      <td>-0.133838</td>\n",
              "      <td>-0.038309</td>\n",
              "      <td>-0.039273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.008850</td>\n",
              "      <td>-0.003067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009524</td>\n",
              "      <td>0.009574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N5</td>\n",
              "      <td>1999-01-01</td>\n",
              "      <td>2008-01-01</td>\n",
              "      <td>In force</td>\n",
              "      <td>unique</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>5810.21</td>\n",
              "      <td>81.39</td>\n",
              "      <td>58102.11</td>\n",
              "      <td>...</td>\n",
              "      <td>0.037712</td>\n",
              "      <td>-0.004430</td>\n",
              "      <td>0.025938</td>\n",
              "      <td>-0.002027</td>\n",
              "      <td>0.022727</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>0.001876</td>\n",
              "      <td>0.000941</td>\n",
              "      <td>-0.011550</td>\n",
              "      <td>-0.026692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a543bcf9-0801-4a81-9fb3-39c2d86f7c31')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a543bcf9-0801-4a81-9fb3-39c2d86f7c31 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a543bcf9-0801-4a81-9fb3-39c2d86f7c31');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4f6f1365-950b-44c1-a0b9-f6af5a2bf574\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4f6f1365-950b-44c1-a0b9-f6af5a2bf574')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4f6f1365-950b-44c1-a0b9-f6af5a2bf574 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64    23\n",
            "object      6\n",
            "int64       1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load\n",
        "df = pd.read_csv(\"/content/Module-3-assignment/eusavingULnoPS.csv\")\n",
        "display(df.head())\n",
        "print(df.dtypes.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k9dGsrG-axlE",
      "metadata": {
        "id": "k9dGsrG-axlE"
      },
      "source": [
        "Our dataset is composed of 30 columns, of which 6 are categorized as 'object', 1 as 64-bit 'integer' (int64) and 23 as 64-bit 'floating-point' (float64) numbers.\n",
        "<br>\n",
        "We shall now check for missing and/or duplicated values before treating them accordingly if any."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "r24UfL7G7M7e",
      "metadata": {
        "id": "r24UfL7G7M7e",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a91f41c-f880-4888-ae96-2e73e708ec97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy.ID              0\n",
            "issue.date             0\n",
            "termination.date       0\n",
            "lapse.reason           0\n",
            "premium.frequency      0\n",
            "gender                 0\n",
            "underwriting.age       0\n",
            "face.amount            0\n",
            "risk.premium           0\n",
            "saving.premium         0\n",
            "CPI.relvar1mth         0\n",
            "CPI.relvar1qtr         0\n",
            "CPI.relvar1yr          0\n",
            "CPI.relvar2yr          0\n",
            "EUidx.relvar1mth       0\n",
            "EUidx.relvar1qtr       0\n",
            "EUidx.relvar1yr        0\n",
            "EUidx.relvar2yr        0\n",
            "rate1Y.relvar1mth      0\n",
            "rate1Y.relvar1qtr      0\n",
            "rate2Y.relvar1mth      0\n",
            "rate2Y.relvar1qtr      0\n",
            "rate10Y.relvar1mth     0\n",
            "rate10Y.relvar1qtr     0\n",
            "unemploy.relvar1mth    0\n",
            "unemploy.relvar1qtr    0\n",
            "industry.relvar1mth    0\n",
            "industry.relvar1qtr    0\n",
            "RTV.relvar1mth         0\n",
            "RTV.relvar1qtr         0\n",
            "dtype: int64\n",
            "Empty DataFrame\n",
            "Columns: [policy.ID, issue.date, termination.date, lapse.reason, premium.frequency, gender, underwriting.age, face.amount, risk.premium, saving.premium, CPI.relvar1mth, CPI.relvar1qtr, CPI.relvar1yr, CPI.relvar2yr, EUidx.relvar1mth, EUidx.relvar1qtr, EUidx.relvar1yr, EUidx.relvar2yr, rate1Y.relvar1mth, rate1Y.relvar1qtr, rate2Y.relvar1mth, rate2Y.relvar1qtr, rate10Y.relvar1mth, rate10Y.relvar1qtr, unemploy.relvar1mth, unemploy.relvar1qtr, industry.relvar1mth, industry.relvar1qtr, RTV.relvar1mth, RTV.relvar1qtr]\n",
            "Index: []\n",
            "\n",
            "[0 rows x 30 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21921 entries, 0 to 21920\n",
            "Data columns (total 30 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   policy.ID            21921 non-null  object \n",
            " 1   issue.date           21921 non-null  object \n",
            " 2   termination.date     21921 non-null  object \n",
            " 3   lapse.reason         21921 non-null  object \n",
            " 4   premium.frequency    21921 non-null  object \n",
            " 5   gender               21921 non-null  object \n",
            " 6   underwriting.age     21921 non-null  int64  \n",
            " 7   face.amount          21921 non-null  float64\n",
            " 8   risk.premium         21921 non-null  float64\n",
            " 9   saving.premium       21921 non-null  float64\n",
            " 10  CPI.relvar1mth       21921 non-null  float64\n",
            " 11  CPI.relvar1qtr       21921 non-null  float64\n",
            " 12  CPI.relvar1yr        21921 non-null  float64\n",
            " 13  CPI.relvar2yr        21921 non-null  float64\n",
            " 14  EUidx.relvar1mth     21921 non-null  float64\n",
            " 15  EUidx.relvar1qtr     21921 non-null  float64\n",
            " 16  EUidx.relvar1yr      21921 non-null  float64\n",
            " 17  EUidx.relvar2yr      21921 non-null  float64\n",
            " 18  rate1Y.relvar1mth    21921 non-null  float64\n",
            " 19  rate1Y.relvar1qtr    21921 non-null  float64\n",
            " 20  rate2Y.relvar1mth    21921 non-null  float64\n",
            " 21  rate2Y.relvar1qtr    21921 non-null  float64\n",
            " 22  rate10Y.relvar1mth   21921 non-null  float64\n",
            " 23  rate10Y.relvar1qtr   21921 non-null  float64\n",
            " 24  unemploy.relvar1mth  21921 non-null  float64\n",
            " 25  unemploy.relvar1qtr  21921 non-null  float64\n",
            " 26  industry.relvar1mth  21921 non-null  float64\n",
            " 27  industry.relvar1qtr  21921 non-null  float64\n",
            " 28  RTV.relvar1mth       21921 non-null  float64\n",
            " 29  RTV.relvar1qtr       21921 non-null  float64\n",
            "dtypes: float64(23), int64(1), object(6)\n",
            "memory usage: 5.0+ MB\n",
            "['policy.ID', 'issue.date', 'termination.date', 'lapse.reason', 'premium.frequency', 'gender', 'underwriting.age', 'face.amount', 'risk.premium', 'saving.premium', 'CPI.relvar1mth', 'CPI.relvar1qtr', 'CPI.relvar1yr', 'CPI.relvar2yr', 'EUidx.relvar1mth', 'EUidx.relvar1qtr', 'EUidx.relvar1yr', 'EUidx.relvar2yr', 'rate1Y.relvar1mth', 'rate1Y.relvar1qtr', 'rate2Y.relvar1mth', 'rate2Y.relvar1qtr', 'rate10Y.relvar1mth', 'rate10Y.relvar1qtr', 'unemploy.relvar1mth', 'unemploy.relvar1qtr', 'industry.relvar1mth', 'industry.relvar1qtr', 'RTV.relvar1mth', 'RTV.relvar1qtr']\n"
          ]
        }
      ],
      "source": [
        "#Potential missing values\n",
        "Missing_Values=df.isna().sum()\n",
        "print(Missing_Values)\n",
        "\n",
        "#Potential duplicated values\n",
        "Duplicated_Values=df[df.duplicated(keep=False)]\n",
        "print(Duplicated_Values)\n",
        "  #Treating duplicated values (if any)\n",
        "df_cleaned=df.drop_duplicates(keep='first')\n",
        "\n",
        "#Information about the new cleaned dataset\n",
        "df_cleaned.info()\n",
        "print(df_cleaned.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099I_dd4bD61",
      "metadata": {
        "id": "099I_dd4bD61"
      },
      "source": [
        "After this check, we can see that there are neither missing values nor duplicates and there are 2 date variables that have been properly treated.\n",
        "\n",
        "We shall now create two datasets (df_cat and df_num), one for each of the following two dependent variables:\n",
        "*   a categorical one: lapse.reason;\n",
        "*   a numeric one: a numerical variable that represents the proportion of risk premium over total premium: proportion_risk_premium = risk.premium / (risk.premium+saving.premium)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "xlLmk_Rsx7vc",
      "metadata": {
        "id": "xlLmk_Rsx7vc"
      },
      "outputs": [],
      "source": [
        "# Conversion of the date columns from 'object' to 'datetime'\n",
        "df_cleaned['issue.date'] = pd.to_datetime(df['issue.date'], errors='coerce')\n",
        "df_cleaned['termination.date'] = pd.to_datetime(df['termination.date'], errors='coerce')\n",
        "\n",
        "# Creation of numerical and categorical datasets\n",
        "df_cat = df_cleaned.copy()\n",
        "df_num = df_cleaned.copy()\n",
        "\n",
        "# Creation of numerical dependent variable\n",
        "df_num['proportion_risk_premium'] = df_num['risk.premium']/(df_num['risk.premium'] + df_num['saving.premium'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XZ5Mhh5DbJ9c",
      "metadata": {
        "id": "XZ5Mhh5DbJ9c"
      },
      "source": [
        "## Data preprocessing\n",
        "After creating the numerical and categorical datasets, we shall now define the X (X_cat and X_num) and y datasets before converting categorical variables to a suitable format (using the \"one-hot encoding\" method), handling date variables and splitting the datasets into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "kxMkhp8KQ01J",
      "metadata": {
        "id": "kxMkhp8KQ01J"
      },
      "outputs": [],
      "source": [
        "# Definition of X and y datasets\n",
        "y_num = df_num['proportion_risk_premium']\n",
        "y_cat = df_cat['lapse.reason']\n",
        "X_num = df_num.drop(['proportion_risk_premium'], axis=1)\n",
        "X_cat = df_cat.drop(['lapse.reason'], axis=1)\n",
        "\n",
        "# One-hot encoding method for categorical variables\n",
        "categorical_cols = X_cat.select_dtypes(include=['object']).columns.tolist()\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_cols)],\n",
        "    remainder='passthrough')\n",
        "\n",
        "# Date variables handling\n",
        "for df_ in [X_num, X_cat]:\n",
        "    df_['issue_date_year'] = df_['issue.date'].dt.year\n",
        "    df_['issue_date_month'] = df_['issue.date'].dt.month\n",
        "    df_['termination_date_year'] = df_['termination.date'].dt.year\n",
        "    df_['termination_date_month'] = df_['termination.date'].dt.month\n",
        "    df_.drop(['issue.date', 'termination.date'], axis=1, inplace=True)\n",
        "\n",
        "# Split test and train datasets\n",
        "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X_cat, y_cat, test_size=0.25, random_state=23, stratify=y_cat)\n",
        "\n",
        "X_train_num, X_test_num, y_train_num, y_test_num = train_test_split(X_num, y_num, test_size=0.25, random_state=23)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XI885gZbJ3Sr",
      "metadata": {
        "id": "XI885gZbJ3Sr"
      },
      "source": [
        "## Development of model for categorical variable: RandomForest\n",
        "\n",
        "In this part we shall develop a Random Forest algorithm for the categorical dependent variable \"lapse.reason\"."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the pipeline with preprocessing and classifier\n",
        "rf_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=23))\n",
        "])\n",
        "\n",
        "# Fitting the model on training data\n",
        "rf_pipeline.fit(X_train_cat, y_train_cat)\n",
        "\n",
        "# Predicting on test data\n",
        "y_pred = rf_pipeline.predict(X_test_cat)\n",
        "\n",
        "# Evaluating the model\n",
        "print(\"Classification report for 'lapse.reason':\")\n",
        "print(classification_report(y_test_cat, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezPnnDZOR33z",
        "outputId": "c8556793-2601-4d8c-c2b9-7a5235356ec3"
      },
      "id": "ezPnnDZOR33z",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for 'lapse.reason':\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Claim       1.00      0.10      0.19        49\n",
            "    In force       1.00      1.00      1.00      3470\n",
            "   Surrender       0.98      1.00      0.99      1962\n",
            "\n",
            "    accuracy                           0.99      5481\n",
            "   macro avg       0.99      0.70      0.72      5481\n",
            "weighted avg       0.99      0.99      0.99      5481\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These results show us that the current model is performing well overall (very high/perfect precision), but poorly on the minority class especially on the claim with a very small recall and we shall tune the model now to see if we can improve it."
      ],
      "metadata": {
        "id": "9zeCBbI3TVk-"
      },
      "id": "9zeCBbI3TVk-"
    },
    {
      "cell_type": "code",
      "source": [
        "param_dist = {\n",
        "    'classifier__n_estimators': [10, 30, 50],\n",
        "    'classifier__max_depth': [None, 10, 20],\n",
        "    'classifier__min_samples_split': [2, 5, 10],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4],\n",
        "    'classifier__max_features': ['sqrt','log2']\n",
        "}\n",
        "\n",
        "# Setting up RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    rf_pipeline, param_distributions=param_dist,\n",
        "    n_iter=20, scoring='f1_weighted', cv=5, n_jobs=-1, verbose=2, random_state=23\n",
        ")\n",
        "\n",
        "# Running hyperparameter tuning\n",
        "random_search.fit(X_train_cat, y_train_cat)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best hyperparameters:\", random_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhgPkMb7TtyM",
        "outputId": "68d1a8d8-3b52-4cf4-8db7-39be117ba189"
      },
      "id": "EhgPkMb7TtyM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Best hyperparameters: {'classifier__n_estimators': 30, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'log2', 'classifier__max_depth': None}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building the pipeline with the best hyperparameters\n",
        "clf_best = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(\n",
        "        n_estimators=30,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        max_features='log2',\n",
        "        max_depth=None,\n",
        "        random_state=23\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Training the classifier\n",
        "clf_best.fit(X_train_cat, y_train_cat)\n",
        "\n",
        "# Predicting on test set\n",
        "y_pred = clf_best.predict(X_test_cat)\n",
        "\n",
        "# Generating classification report\n",
        "print(\"Classification Report with best hyperparameters:\")\n",
        "print(classification_report(y_test_cat, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7zWRZ_IgC4Q",
        "outputId": "8b27aa34-2dea-4c33-a890-a13700af95d6"
      },
      "id": "u7zWRZ_IgC4Q",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report with best hyperparameters:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Claim       1.00      0.12      0.22        49\n",
            "    In force       1.00      1.00      1.00      3470\n",
            "   Surrender       0.98      1.00      0.99      1962\n",
            "\n",
            "    accuracy                           0.99      5481\n",
            "   macro avg       0.99      0.71      0.74      5481\n",
            "weighted avg       0.99      0.99      0.99      5481\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After the hyperparameter tuning, we observe that the high overall accuracy is still driven mainly by majority classes, the model is still perfoming well and there is a small improvement in the Claim recall (from 10% to 12%), which shows that the model still struggles to detect claims effectively."
      ],
      "metadata": {
        "id": "VR6AswWshb5l"
      },
      "id": "VR6AswWshb5l"
    },
    {
      "cell_type": "markdown",
      "id": "Bc1ljHyeKQCj",
      "metadata": {
        "id": "Bc1ljHyeKQCj"
      },
      "source": [
        "## Development of model for numerical variable (proportion): Sequential Dense NN\n",
        "\n",
        "\n",
        "In this section we shall develop a Sequential Dense Neural Network for the numerical variable \"proportion_risk_premium\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4_-XSP6_58ah",
      "metadata": {
        "id": "4_-XSP6_58ah",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "7a3595ef-d293-49cf-9b86-47cc24f7fa99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 2.0801e-05 - mae: 0.0037\n",
            "Test MAE: 0.0036078321281820536\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Setting seeds for reproducibility\n",
        "seed_value = 23\n",
        "random.seed(seed_value)\n",
        "np.random.seed(seed_value)\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "# One-hot encoding method for categorical variables\n",
        "categorical_cols_num = X_train_num.select_dtypes(include=['object']).columns.tolist()\n",
        "preprocessor_num = ColumnTransformer(transformers=[('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols_num)],\n",
        "    remainder='passthrough')\n",
        "\n",
        "# Fitting and transforming the training and testing datasets\n",
        "X_train_encoded_num = preprocessor_num.fit_transform(X_train_num)\n",
        "X_test_encoded_num = preprocessor_num.transform(X_test_num)\n",
        "\n",
        "X_train_dense_num = X_train_encoded_num.toarray() if hasattr(X_train_encoded_num, \"toarray\") else X_train_encoded_num\n",
        "X_test_dense_num = X_test_encoded_num.toarray() if hasattr(X_test_encoded_num, \"toarray\") else X_test_encoded_num\n",
        "\n",
        "# Scaling all features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_num = scaler.fit_transform(X_train_dense_num)\n",
        "X_test_scaled_num = scaler.transform(X_test_dense_num)\n",
        "\n",
        "# Defining the neural network\n",
        "nn_model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_scaled_num.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Model compilation\n",
        "nn_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Model training\n",
        "history = nn_model.fit(\n",
        "    X_train_scaled_num,\n",
        "    y_train_num,\n",
        "    validation_split=0.25,\n",
        "    epochs=50,\n",
        "    batch_size=32,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Model evaluation\n",
        "loss, mae = nn_model.evaluate(X_test_scaled_num, y_test_num)\n",
        "print(f\"Test MAE: {mae}\")\n",
        "\n",
        "# Plot training history\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the results above we can say that, with the average absolute error (MAE) in predicting \"proportion_risk_premium\" of 0.36%, the model is highly accurate at estimating the target variable on unseen data and that the model has effectively learned the relationship between features and the \"proportion_risk_premium\"."
      ],
      "metadata": {
        "id": "4eZoEEbG4D3K"
      },
      "id": "4eZoEEbG4D3K"
    },
    {
      "cell_type": "markdown",
      "id": "8RSD2zs9TRUh",
      "metadata": {
        "id": "8RSD2zs9TRUh"
      },
      "source": [
        "# Variable selection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FlXxBhvuFhfS",
      "metadata": {
        "id": "FlXxBhvuFhfS"
      },
      "source": [
        "## Categorical problem, feature selection\n",
        "\n",
        "In this section, we shall perform Boruta feature selection, using (from boruta) BortutaPy, for the categorical dependent variable \"lapse.reason\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "VlXLu31W5snq",
      "metadata": {
        "id": "VlXLu31W5snq"
      },
      "outputs": [],
      "source": [
        "# Fit the preprocessor on training data\n",
        "preprocessor.fit(X_train_cat)\n",
        "\n",
        "# Transform train and test features\n",
        "X_train_encoded = preprocessor.transform(X_train_cat)\n",
        "X_test_encoded = preprocessor.transform(X_test_cat)\n",
        "\n",
        "# Convert to dense numpy arrays\n",
        "X_train_dense = X_train_encoded if hasattr(X_train_encoded, \"toarray\") else X_train_encoded\n",
        "X_test_dense = X_test_encoded if hasattr(X_test_encoded, \"toarray\") else X_test_encoded\n",
        "\n",
        "if hasattr(X_train_dense, \"toarray\"):\n",
        "    X_train_dense = X_train_dense.toarray()\n",
        "if hasattr(X_test_dense, \"toarray\"):\n",
        "    X_test_dense = X_test_dense.toarray()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now fit Boruta\n",
        "rf = RandomForestClassifier(n_estimators=10, random_state=23)\n",
        "selector = BorutaPy(rf, max_iter=5, random_state=23, verbose=0)\n",
        "selector.fit(X_train_dense, y_train_cat.values)\n",
        "\n",
        "# Getting feature names after encoding\n",
        "feature_names = np.array(preprocessor.get_feature_names_out())\n",
        "selected_features = feature_names[selector.support_]\n",
        "\n",
        "print(\"Boruta selected features:\")\n",
        "print(list(selected_features))"
      ],
      "metadata": {
        "id": "QZLG3FGm9-Be",
        "outputId": "eb4f0a07-1d51-404e-9446-1312915a15bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "QZLG3FGm9-Be",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Boruta selected features:\n",
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unfortunately, for the boruta feature selection we were not able to get feature selections after 25 minuts of run due to the hugeness of the data; i.e, for us to get more precise information, we would need to use more estimators (50 or 100) and increase the maximum number of iterations (20 or more) but doing this makes our program crash due to lack of RAM."
      ],
      "metadata": {
        "id": "q8p8njpVGJXT"
      },
      "id": "q8p8njpVGJXT"
    },
    {
      "cell_type": "markdown",
      "id": "HMDLAYd75uph",
      "metadata": {
        "id": "HMDLAYd75uph"
      },
      "source": [
        "In this section we shall perform Genetic Algorithm feature selection using (from deap) base, creator, tools, algorithms respectively for the categorical dependent variable \"lapse.reason\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "sY9sH1S95zke",
      "metadata": {
        "id": "sY9sH1S95zke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "43cbaed9-a5c9-4c7c-e83b-efd3dc07bd3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
            "/usr/local/lib/python3.12/dist-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
            "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generation 1: Best accuracy = 0.992\n",
            "Generation 2: Best accuracy = 0.992\n",
            "Generation 3: Best accuracy = 0.992\n",
            "Generation 4: Best accuracy = 0.992\n",
            "Generation 5: Best accuracy = 0.992\n",
            "Generation 6: Best accuracy = 0.992\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3473380730.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNGEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0moffspring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvarAnd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcxpb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutpb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mfits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoolbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffspring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffspring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfitness\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3473380730.py\u001b[0m in \u001b[0;36mevalFitness\u001b[0;34m(individual)\u001b[0m\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_selected\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m     cv_results = cross_validate(\n\u001b[0m\u001b[1;32m    685\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;31m# independent, and that it is pickle-able.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m     results = parallel(\n\u001b[0m\u001b[1;32m    412\u001b[0m         delayed(_fit_and_score)(\n\u001b[1;32m    413\u001b[0m             \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Defining the fitness evaluation function\n",
        "def evalFitness(individual):\n",
        "    if sum(individual) == 0:\n",
        "        return 0.,\n",
        "    selected_indices = [i for i, bit in enumerate(individual) if bit == 1]\n",
        "    X_selected = X_train_encoded[:, selected_indices]\n",
        "    clf = RandomForestClassifier(\n",
        "        n_estimators=30,\n",
        "        max_depth=None,\n",
        "        min_samples_split=2,\n",
        "        min_samples_leaf=1,\n",
        "        max_features='log2',\n",
        "        class_weight='balanced',\n",
        "        n_jobs=-1,\n",
        "        random_state=23\n",
        "    )\n",
        "\n",
        "    scores = cross_val_score(clf, X_selected, y_train_cat, cv=3, scoring='accuracy')\n",
        "    return scores.mean(),\n",
        "\n",
        "# DEAP setup\n",
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
        "n_features = X_train_encoded.shape[1]\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_bool, n=n_features)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n",
        "# Genetic operators registration\n",
        "toolbox.register(\"evaluate\", evalFitness)\n",
        "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
        "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
        "\n",
        "# Genetic Algorithm run\n",
        "seed_value = 23\n",
        "random.seed(seed_value)\n",
        "population = toolbox.population(n=30)\n",
        "NGEN = 5\n",
        "\n",
        "for gen in range(NGEN):\n",
        "    offspring = algorithms.varAnd(population, toolbox, cxpb=0.5, mutpb=0.2)\n",
        "    fits = list(map(toolbox.evaluate, offspring))\n",
        "    for fit, ind in zip(fits, offspring):\n",
        "        ind.fitness.values = fit\n",
        "    population = toolbox.select(offspring, len(population))\n",
        "    best_ind = tools.selBest(population, 1)[0]\n",
        "    print(f\"Generation {gen+1}: Best accuracy = {best_ind.fitness.values[0]:.3f}\")\n",
        "\n",
        "# Extracting the best feature subset\n",
        "best_individual = tools.selBest(population, 1)[0]\n",
        "selected_indices_GA = [i for i, bit in enumerate(best_individual) if bit == 1]\n",
        "selected_features_GA = [X_train_encoded.columns[i] for i in selected_indices]\n",
        "\n",
        "print(\"Selected features by GA:\", selected_features_GA)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As for Genetic Algorithm feature selection I was not able to run the code and extract results due to the lack of RAM on my Google Colab account (code too powerful I suppose since it kept crashing)."
      ],
      "metadata": {
        "id": "tfBore-WiWWq"
      },
      "id": "tfBore-WiWWq"
    },
    {
      "cell_type": "markdown",
      "id": "70jdGydFFon-",
      "metadata": {
        "id": "70jdGydFFon-"
      },
      "source": [
        "## Numerical problem, feature selection\n",
        "\n",
        "In this section, we start by performing a forward and a backward selection on explanatory variables for the numerical variable \"proportion_risk_premium\".\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "lltiuzAZyXWt",
      "metadata": {
        "id": "lltiuzAZyXWt",
        "outputId": "d3335ca2-94fa-459f-f32a-800d504a4222",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'SequentialFeatureSelector' object has no attribute 'get_support'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1287183777.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Getting selected feature names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mforward_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msfs_forward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mbackward_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msfs_backward\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SequentialFeatureSelector' object has no attribute 'get_support'"
          ]
        }
      ],
      "source": [
        "# Selecting only numeric columns\n",
        "numeric_cols = X_train_num.select_dtypes(include=['number']).columns.tolist()\n",
        "\n",
        "# Subseting data to only numeric features and scaling them\n",
        "X_train_num_numeric = X_train_num[numeric_cols]\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled_numeric = scaler.fit_transform(X_train_num_numeric)\n",
        "\n",
        "# Running forward feature selection\n",
        "sfs_forward = SequentialFeatureSelector(\n",
        "    Lasso(alpha=0.01),\n",
        "    k_features=10,\n",
        "    forward=True\n",
        ")\n",
        "sfs_forward.fit(X_train_scaled_numeric, y_train_num)\n",
        "\n",
        "# Running backward feature selection\n",
        "sfs_backward = SequentialFeatureSelector(\n",
        "    Lasso(alpha=0.001),\n",
        "    k_features=10,\n",
        "    forward=False\n",
        ")\n",
        "sfs_backward.fit(X_train_scaled_numeric, y_train_num)\n",
        "\n",
        "# Getting selected feature names\n",
        "forward_indices = sfs_forward.get_support(indices=True)\n",
        "backward_indices = sfs_backward.get_support(indices=True)\n",
        "\n",
        "# Mapping indices to feature names\n",
        "forward_features = X_train_num_numeric.columns[forward_indices]\n",
        "backward_features = X_train_num_numeric.columns[backward_indices]\n",
        "\n",
        "print(\"Forward selected features:\", list(forward_features))\n",
        "print(\"Backward selected features:\", list(backward_features))\n",
        "\n",
        "# Using forward-selected features for model training\n",
        "X_train_final_num = X_train_num[forward_features]\n",
        "X_test_final_num = X_test_num[forward_features]\n",
        "\n",
        "# Scale the final features\n",
        "X_train_final_num_scaled = scaler.fit_transform(X_train_final_num)\n",
        "X_test_final_num_scaled = scaler.transform(X_test_final_num)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BJlJAwZQ6_pO",
      "metadata": {
        "id": "BJlJAwZQ6_pO"
      },
      "source": [
        "Then we apply Lasso on that same numerical variable \"proportion_risk_premium\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IOfqUffz7ATL",
      "metadata": {
        "id": "IOfqUffz7ATL",
        "outputId": "4b262fa1-f752-49d2-903b-96b6b9cd33cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso coefficients for selected features:\n",
            "underwriting.age    0.0\n",
            "face.amount        -0.0\n",
            "risk.premium        0.0\n",
            "saving.premium     -0.0\n",
            "CPI.relvar1mth      0.0\n",
            "CPI.relvar1qtr      0.0\n",
            "CPI.relvar1yr       0.0\n",
            "CPI.relvar2yr       0.0\n",
            "EUidx.relvar1mth    0.0\n",
            "EUidx.relvar1qtr    0.0\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Extracting the selected feature names\n",
        "selected_features_Lasso = list(forward_features)\n",
        "\n",
        "# Subsetting the original data to these features\n",
        "X_train_selected_num = X_train_num[selected_features_Lasso]\n",
        "X_test_selected_num = X_test_num[selected_features_Lasso]\n",
        "\n",
        "# Scaling the features\n",
        "scaler_final = StandardScaler()\n",
        "X_train_scaled = scaler_final.fit_transform(X_train_selected_num)\n",
        "X_test_scaled = scaler_final.transform(X_test_selected_num)\n",
        "\n",
        "# Fitting Lasso regression\n",
        "lasso_final = Lasso(alpha=0.001)\n",
        "lasso_final.fit(X_train_scaled, y_train_num)\n",
        "\n",
        "# Coefficients for interpretability\n",
        "coefficients = pd.Series(lasso_final.coef_, index=selected_features_Lasso)\n",
        "\n",
        "print(\"Lasso coefficients for selected features:\")\n",
        "print(coefficients.sort_values(ascending=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The coefficients our selected features are all zero after applying Lasso, which indicates none of these features have a significant linear relationship with \"proportion_risk_premium\" under the current model and alpha value; this may also suggest that the relationship might be non-linear or weak."
      ],
      "metadata": {
        "id": "CMbmpaCWZ5jf"
      },
      "id": "CMbmpaCWZ5jf"
    },
    {
      "cell_type": "markdown",
      "id": "TDgCQsykrs_5",
      "metadata": {
        "id": "TDgCQsykrs_5"
      },
      "source": [
        "# Explainability of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e_UZkcj2rw89",
      "metadata": {
        "id": "e_UZkcj2rw89"
      },
      "source": [
        "## Categorical problem\n",
        "\n",
        "In this section, we give explanations of the RandomForest model, by permutation feature selection and using \"permutation_importance\", to a client who is keen to understand the reason behind the fact that their quote is so high."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Compute permutation importance on the test set\n",
        "result = permutation_importance(\n",
        "    clf_best, X_test_cat, y_test_cat, n_repeats=10, random_state=23, n_jobs=-1\n",
        ")\n",
        "\n",
        "# 2. Get feature names from the preprocessor used in the pipeline\n",
        "# This assumes the preprocessor has a ColumnTransformer or similar\n",
        "preprocessor = clf_best.named_steps['preprocessor']\n",
        "# Get feature names after preprocessing\n",
        "try:\n",
        "    feature_names = preprocessor.get_feature_names_out()\n",
        "except AttributeError:\n",
        "    # If get_feature_names_out() is not available, fallback\n",
        "    # For example, if using older versions or different preprocessors\n",
        "    # You might need to manually construct feature names\n",
        "    feature_names = []\n",
        "\n",
        "# 3. Check if feature_names matches the shape of importance scores\n",
        "if len(feature_names) == len(result.importances_mean):\n",
        "    importance_scores = pd.Series(result.importances_mean, index=feature_names)\n",
        "else:\n",
        "    # If the lengths don't match, this indicates a mismatch\n",
        "    # You may need to handle this case accordingly\n",
        "    print(\"Mismatch between feature names and importance scores. Please verify the preprocessing steps.\")\n",
        "    importance_scores = pd.Series(result.importances_mean)\n",
        "\n",
        "# 4. Visualize the top 20 most important features\n",
        "plt.figure(figsize=(12,8))\n",
        "importance_scores.sort_values(ascending=False).head(20).plot.bar()\n",
        "plt.title('Top 20 Features Impacting Quote Prediction')\n",
        "plt.ylabel('Mean Decrease in Model Performance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 5. Interpret the results for the client\n",
        "top_features = importance_scores.sort_values(ascending=False).head(10).index.tolist()\n",
        "print(\"The most influential features in determining the quote are:\")\n",
        "for feat in top_features:\n",
        "    print(f\"- {feat}\")\n",
        "\n",
        "print(\"\\nPlain-language explanation:\")\n",
        "print(\"Features like the risk premium, face amount, and policy age are among the most impactful.\")\n",
        "print(\"Higher risk premiums and larger face amounts tend to increase the quote, which helps explain the high quotes.\")\n"
      ],
      "metadata": {
        "id": "_sv8O6cQcOa2"
      },
      "id": "_sv8O6cQcOa2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Possible interpretation for a client:\n",
        "\"The importance scores tell us which features most influence the model's output. For example, if certain age groups, face amounts, or risk premiums have high importance, it means these factors significantly impact the quote.\n",
        "\n",
        "If the model indicates that 'risk premium' or 'face amount' are highly influential, it suggests that higher risk or larger face amounts tend to lead to higher quotes.\n",
        "\n",
        "Understanding these key factors helps us explain why a quote might be high—it's driven by the most important features identified by the model."
      ],
      "metadata": {
        "id": "OxlQcm_7J-wR"
      },
      "id": "OxlQcm_7J-wR"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"The features that most influence the quote include the risk premium, face amount, and policy age. When these features are high—say, a large face amount or a high risk premium—the model tends to predict a higher quote. This makes sense because policies with higher risk or larger coverage are typically more expensive, and this is reflected in the model’s important factors.\""
      ],
      "metadata": {
        "id": "jDvMiyFckV1r"
      },
      "id": "jDvMiyFckV1r"
    },
    {
      "cell_type": "markdown",
      "id": "6ogt_2Kv9GF6",
      "metadata": {
        "id": "6ogt_2Kv9GF6"
      },
      "source": [
        "For the other method, of our choice, to explain the RandomForest model we chose the SHAP (SHapley Additive exPlanations) method as it provides local explanations (for individual predictions) and global explanations (feature importance across the dataset), in addition to being considered state-of-the-art for model interpretability. Moreover, it provides summary plots to see overall feature importance and effects, offers consistent and local explanations and helps when visualizing feature contributions for any specific prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "Jxe13YHE9LCB",
      "metadata": {
        "id": "Jxe13YHE9LCB",
        "outputId": "515b721d-f877-4102-9956-41ac606fda70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'shap' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1185749566.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Creating SHAP explainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTreeExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Selecting raw data sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'shap' is not defined"
          ]
        }
      ],
      "source": [
        "# Extracting the model\n",
        "rf_model = clf_best.named_steps['classifier']\n",
        "\n",
        "# Creating SHAP explainer\n",
        "explainer = shap.TreeExplainer(rf_model)\n",
        "\n",
        "# Selecting raw data sample\n",
        "X_sample_raw = X_test_cat[:100]\n",
        "\n",
        "# Transforming using the pipeline's preprocessor\n",
        "X_sample_transformed = clf_best.named_steps['preprocessor'].transform(X_sample_raw)\n",
        "\n",
        "# Checking if sparse\n",
        "if sparse.issparse(X_sample_transformed):\n",
        "    X_sample_dense = X_sample_transformed.toarray()\n",
        "else:\n",
        "    X_sample_dense = X_sample_transformed\n",
        "\n",
        "# Converting to float\n",
        "X_sample_dense = X_sample_dense.astype(float)\n",
        "\n",
        "# Using with SHAP\n",
        "shap_values = explainer.shap_values(X_sample_dense)\n",
        "\n",
        "# Plot\n",
        "shap.summary_plot(shap_values, features=X_sample_dense, feature_names=feature_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eS87my6hx_3N",
      "metadata": {
        "id": "eS87my6hx_3N"
      },
      "source": [
        "## Numerical problem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Eh90ACcpr4XT",
      "metadata": {
        "id": "Eh90ACcpr4XT"
      },
      "source": [
        "In this section we shall explain neural networks with SHAP's KernelExplainer, a model-agnostic method, which is commonly used as it estimates feature contributions by approximating Shapley values instead of the SHAP method which is more complex than tree-based models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "a3BMxP6m9Sij",
      "metadata": {
        "id": "a3BMxP6m9Sij",
        "outputId": "2d7aeddc-eaff-44e8-947d-fbf1d6ee477b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train_scaled_num' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2799164523.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Selecting background samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbackground\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_scaled_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Creating the KernelExplainer with the model's prediction function and background data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_scaled_num' is not defined"
          ]
        }
      ],
      "source": [
        "predict_nn = lambda x: nn_model.predict(x)\n",
        "\n",
        "# Selecting background samples\n",
        "background = X_train_scaled_num[np.random.choice(X_train_scaled_num.shape[0], 100, replace=False)]\n",
        "\n",
        "# Creating the KernelExplainer with the model's prediction function and background data\n",
        "explainer = shap.KernelExplainer(predict_nn, background)\n",
        "\n",
        "# Selecting a subset of test data for explanation\n",
        "X_test_sample_num = X_test_scaled_num[:100]\n",
        "\n",
        "# Computing SHAP values\n",
        "shap_values = explainer.shap_values(X_test_sample_num, nsamples=100)\n",
        "\n",
        "# 5. Plot SHAP summary\n",
        "shap.summary_plot(shap_values, features=X_test_sample_num, feature_names=feature_names)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpretation for the client:\n",
        "\"SHAP explains how each feature influences your quote. For example, a high 'risk premium' or 'face amount' might increase the predicted quote, while other features like age or unemployment rate could decrease it.\n",
        "\n",
        "The SHAP summary plot shows, across many sample quotes, which features are most influential overall. If 'risk premium' and 'face amount' are at the top with positive SHAP values, they tend to drive the quote higher. Conversely, features with negative SHAP values reduce the quote prediction.\n",
        "\n",
        "This explanation helps us understand exactly why the neural network predicts a high quote—it's based on the most impactful features we've identified clearly with SHAP.\""
      ],
      "metadata": {
        "id": "VDuQX4nwLIbc"
      },
      "id": "VDuQX4nwLIbc"
    },
    {
      "cell_type": "markdown",
      "id": "aRttCOde6rMA",
      "metadata": {
        "id": "aRttCOde6rMA"
      },
      "source": [
        "# BIAS for the numerical problem\n",
        "\n",
        "In this section we shall define a variable called \"risk_category\" that takes values High or Low if variable \"proportion_risk_premium\" is higher or lower than the treshold = 0.0002 = 0.02%.\n",
        "\n",
        "Similarly, we shall define the variable \"risk_category_pred\" that does the same but on the basis of the values predicted by the Neural Network model.\n",
        "\n",
        "We shall also count the number of High and Low values for Females and Males for these two variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "Catz0tFI4SXm",
      "metadata": {
        "id": "Catz0tFI4SXm",
        "outputId": "881c6c71-2d2e-4042-a856-d276e8a79292",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2755236304.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'risk_category'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'proportion_risk_premium'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Low'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpredicted_proportions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Creating 'risk_category_pred' based on predicted values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn_model' is not defined"
          ]
        }
      ],
      "source": [
        "# Threshold = 0.0002 = 0.02%\n",
        "threshold = 0.0002\n",
        "\n",
        "df_num['risk_category'] = np.where(df_num['proportion_risk_premium'] > threshold, 'High', 'Low')\n",
        "predicted_proportions = nn_model.predict(X_test_scaled_num).flatten()\n",
        "\n",
        "# Creating 'risk_category_pred' based on predicted values\n",
        "df_num.loc[df_num.index[:len(predicted_proportions)], 'risk_category_pred'] = np.where(\n",
        "    predicted_proportions > threshold, 'High', 'Low')\n",
        "\n",
        "# Counting the number of High/Low for Females and Males for true categories\n",
        "counts_true = df_num.groupby(['gender', 'risk_category']).size().unstack(fill_value=0)\n",
        "\n",
        "# Counting the number of High/Low for Females and Males for predicted categories\n",
        "counts_pred = df_num.groupby(['gender', 'risk_category_pred']).size().unstack(fill_value=0)\n",
        "\n",
        "# Displaying the counts\n",
        "print(\"Counts for true risk categories:\")\n",
        "print(counts_true)\n",
        "\n",
        "print(\"\\nCounts for predicted risk categories:\")\n",
        "print(counts_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The true risk labels show that approximately 83% of females (6,994 out of 8,445) and 72% of males (9,647 out of 13,476) are categorized as high risk. However, the model's predictions significantly underrepresent these high-risk groups, with only 1,876 females and 3,605 males predicted as high risk, way less than the actual counts.\n",
        "\n",
        "This indicates that the model is conservative in assigning high risk, especially for females, and tends to underestimate the number of individuals truly at high risk."
      ],
      "metadata": {
        "id": "NJLyS3rOJIfP"
      },
      "id": "NJLyS3rOJIfP"
    },
    {
      "cell_type": "markdown",
      "id": "L4N1ibk-gKT_",
      "metadata": {
        "id": "L4N1ibk-gKT_"
      },
      "source": [
        "Now we shall use the confusion_matrix to compare real and predicted values by counting: False positives, False negatives, Trues positives, True negatives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S5pT4BN15p5H",
      "metadata": {
        "id": "S5pT4BN15p5H",
        "outputId": "cc1fab8b-117d-4f12-d021-648acc2e7e76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'<' not supported between instances of 'float' and 'str'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3968236.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 1. Compute confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'risk_category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_num\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'risk_category_pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'High'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Low'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# 2. Extract counts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    338\u001b[0m     \"\"\"\n\u001b[1;32m    339\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattach_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_pred\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name, raise_unknown)\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_row_or_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mfirst_row_or_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfirst_row_or_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mcached_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_row_or_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;31m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_unique.py\u001b[0m in \u001b[0;36mcached_unique\u001b[0;34m(xp, *ys)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mUnique\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cached_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_unique.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mUnique\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0mof\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cached_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_unique.py\u001b[0m in \u001b[0;36m_cached_unique\u001b[0;34m(y, xp)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mxp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_namespace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36munique_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munique_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_arraysetops_impl.py\u001b[0m in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m         ret = _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0m\u001b[1;32m    290\u001b[0m                         equal_nan=equal_nan, inverse_shape=ar.shape, axis=None)\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unpack_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_arraysetops_impl.py\u001b[0m in \u001b[0;36m_unique1d\u001b[0;34m(ar, return_index, return_inverse, return_counts, equal_nan, inverse_shape, axis)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maux\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
          ]
        }
      ],
      "source": [
        "cm = confusion_matrix(df_num['risk_category'], df_num['risk_category_pred'], labels=['High', 'Low'])\n",
        "\n",
        "# Extracting the counts\n",
        "TP = cm[0, 0]  # True Positives: predicted 'High' and actually 'High'\n",
        "FN = cm[0, 1]  # False Negatives: predicted 'Low' but actually 'High'\n",
        "FP = cm[1, 0]  # False Positives: predicted 'High' but actually 'Low'\n",
        "TN = cm[1, 1]  # True Negatives: predicted 'Low' and actually 'Low'\n",
        "\n",
        "# Printing results\n",
        "print(f\"Confusion Matrix:\\n{cm}\\n\")\n",
        "print(f\"True Positives (High correctly predicted): {TP}\")\n",
        "print(f\"False Negatives (High but predicted Low): {FN}\")\n",
        "print(f\"False Positives (Low but predicted High): {FP}\")\n",
        "print(f\"True Negatives (Low correctly predicted): {TN}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_iXYHCM_HsNY",
      "metadata": {
        "id": "_iXYHCM_HsNY"
      },
      "source": [
        "## Metrics to detect possible bias on predicted values\n",
        "In this section we investigate possible bias on the basis of the metrics:\n",
        "\n",
        "\n",
        "*   Demographic Parity (no bias range: -0.1, 0.1)\n",
        "*   Equal Opportunity (no bias range: -0.1, 0.1)\n",
        "*   Average Odds (no bias range: -0.1, 0.1)\n",
        "*   Disparate Impact (no bias range: 0.8, 1.25)\n",
        "*   Theil Index (no bias range: 0, 0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dB_-avSf5nLM",
      "metadata": {
        "id": "dB_-avSf5nLM",
        "outputId": "8a98bf16-3448-43a6-b84e-2bb2383f9486",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Demographic Parity Difference: 0.284\n"
          ]
        }
      ],
      "source": [
        "# 1. Calculate positive outcome rates per group\n",
        "groups = ['gender']  # or any other demographic variable\n",
        "\n",
        "results = []\n",
        "\n",
        "for group in groups:\n",
        "    for outcome in ['risk_category', 'risk_category_pred']:\n",
        "        # Calculate positive rate for each group\n",
        "        group_rates = df_num.groupby(group)[outcome].value_counts(normalize=True).unstack()\n",
        "        # e.g., group_rates.loc[:, 'High'] gives positive rate for 'High'\n",
        "\n",
        "        # Store for metrics calculation\n",
        "        results.append({\n",
        "            'group': group,\n",
        "            'outcome': outcome,\n",
        "            'rates': group_rates\n",
        "        })\n",
        "\n",
        "# 2. Compute metrics\n",
        "# For simplicity, let's define functions for each metric\n",
        "\n",
        "def demographic_parity_diff(rates_group1, rates_group2):\n",
        "    return abs(rates_group1 - rates_group2).max()\n",
        "\n",
        "def equal_opportunity_diff(tpr_group1, tpr_group2):\n",
        "    return abs(tpr_group1 - tpr_group2).max()\n",
        "\n",
        "def average_odds_diff(tpr1, fpr1, tpr2, fpr2):\n",
        "    return 0.5 * (abs(tpr1 - tpr2) + abs(fpr1 - fpr2))\n",
        "\n",
        "def disparate_impact_ratio(rate_group1, rate_group2):\n",
        "    return rate_group1 / rate_group2 if rate_group2 != 0 else np.inf\n",
        "\n",
        "def theil_index(rates):\n",
        "    # Normalize to sum to 1\n",
        "    rates = np.array(rates)\n",
        "    rates = rates / rates.sum()\n",
        "    return np.sum(rates * np.log(rates / rates.mean()))\n",
        "\n",
        "# 3. Example: Calculate and compare metrics between groups\n",
        "# (You need to define the groups and outcomes; this is illustrative)\n",
        "\n",
        "# For each pair of groups, compute these metrics\n",
        "# Example for gender groups\n",
        "group1_rates = results[0]['rates']['High']\n",
        "group2_rates = results[1]['rates']['High']\n",
        "\n",
        "dp_diff = demographic_parity_diff(group1_rates, group2_rates)\n",
        "# For equal opportunity, you'd need TPRs per group\n",
        "# Similarly for other metrics\n",
        "\n",
        "print(f\"Demographic Parity Difference: {dp_diff:.3f}\")\n",
        "# Check if within acceptable range (-0.1, 0.1)\n",
        "\n",
        "# Note: Full implementation requires calculating TPRs, FPRs, and applying formulas per metric\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does this number mean?\n",
        "The value 0.284 (or approximately 28.4%) reflects the maximum absolute difference in positive outcome rates between groups.\n",
        "In your specific calculation, it compares the rate at which each group receives a positive label ('High') in your dataset.\n",
        "Interpreting the value:\n",
        "Close to 0: Perfect fairness — the positive outcome rate is nearly identical across groups.\n",
        "Values near 1: Highly disparate — one group has a much higher or lower positive rate than the other.\n",
        "Your value (0.284): Indicates a moderate disparity—about a 28.4% difference in positive rates between the groups."
      ],
      "metadata": {
        "id": "4cj_MjRoIahA"
      },
      "id": "4cj_MjRoIahA"
    },
    {
      "cell_type": "markdown",
      "id": "x44KYE-fPC8F",
      "metadata": {
        "id": "x44KYE-fPC8F"
      },
      "source": [
        "## Bias mitigation\n",
        "Here we proceed with:\n",
        "\n",
        "*   Preprocessing bias mitigation: choose the method, between reweighing and optimized preprocessing, that leads to a greater bias reduction\n",
        "*   In-processing bias mitigation:  choose the method, between Meta Fair\n",
        "*   Postprocessing bias mitigation: Reject option classification and equalized Odds\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x3S88Rug5n_r",
      "metadata": {
        "id": "x3S88Rug5n_r",
        "outputId": "8485b97b-474c-441a-eacb-a4642c128c22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: could not convert string to float: 'N1'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "DataFrame values must be numerical.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/aif360/datasets/structured_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, label_names, protected_attribute_names, instance_weights_name, scores_names, unprivileged_protected_attributes, privileged_protected_attributes, metadata)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6643\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6644\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         return self.apply(\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_astype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'N1'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1209596656.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Convert your dataset into AIF360 format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryLabelDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'risk_category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotected_attribute_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Apply Reweighing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/aif360/datasets/binary_label_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, favorable_label, unfavorable_label, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfavorable_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfavorable_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBinaryLabelDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/aif360/datasets/structured_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, label_names, protected_attribute_names, instance_weights_name, scores_names, unprivileged_protected_attributes, privileged_protected_attributes, metadata)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ValueError: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame values must be numerical.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# Convert all column names to strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: DataFrame values must be numerical."
          ]
        }
      ],
      "source": [
        "# Preprocessing\n",
        "# Example: Using AIF360 Reweighing to reduce bias before training\n",
        "\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "\n",
        "# Convert your dataset into AIF360 format\n",
        "dataset = BinaryLabelDataset(df=df, label_names=['risk_category'], protected_attribute_names=['gender'])\n",
        "\n",
        "# Apply Reweighing\n",
        "RW = Reweighing()\n",
        "dataset_transformed = RW.fit_transform(dataset)\n",
        "\n",
        "# Use the sample weights in training (if your classifier supports sample weights)\n",
        "sample_weights = dataset_transformed.instance_weights\n",
        "\n",
        "# Now train your classifier with sample_weights\n",
        "# Example:\n",
        "clf = RandomForestClassifier(n_estimators=50, class_weight=None, random_state=42)\n",
        "clf.fit(X_train, y_train, sample_weight=sample_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9QXy7m2U9gIh",
      "metadata": {
        "id": "9QXy7m2U9gIh",
        "outputId": "ad76dd60-8bb1-48cf-afd0-53f02e4dc9d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: could not convert string to float: 'N1'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "DataFrame values must be numerical.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/aif360/datasets/structured_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, label_names, protected_attribute_names, instance_weights_name, scores_names, unprivileged_protected_attributes, privileged_protected_attributes, metadata)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6643\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6644\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor_from_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m         return self.apply(\n\u001b[0m\u001b[1;32m    431\u001b[0m             \u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m                 \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 758\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    759\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_astype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/astype.py\u001b[0m in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'N1'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3461802066.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Prepare dataset for AIF360\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBinaryLabelDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'risk_category'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotected_attribute_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Initialize MetaFairClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/aif360/datasets/binary_label_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, favorable_label, unfavorable_label, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munfavorable_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munfavorable_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBinaryLabelDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/aif360/datasets/structured_dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, df, label_names, protected_attribute_names, instance_weights_name, scores_names, unprivileged_protected_attributes, privileged_protected_attributes, metadata)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ValueError: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"DataFrame values must be numerical.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# Convert all column names to strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: DataFrame values must be numerical."
          ]
        }
      ],
      "source": [
        "# In-processing\n",
        "# Using AIF360 Meta Fair Classifier (In-processing)\n",
        "from aif360.algorithms.inprocessing import MetaFairClassifier\n",
        "\n",
        "# Prepare dataset for AIF360\n",
        "dataset = BinaryLabelDataset(df=df, label_names=['risk_category'], protected_attribute_names=['gender'])\n",
        "\n",
        "# Initialize MetaFairClassifier\n",
        "mfc = MetaFairClassifier()\n",
        "\n",
        "# Train\n",
        "mfc.fit(dataset)\n",
        "\n",
        "# Get predictions\n",
        "pred_dataset = mfc.predict(dataset)\n",
        "\n",
        "# Convert predictions back to your data format\n",
        "pred_labels = pred_dataset.labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CRxLAFPz9i-x",
      "metadata": {
        "id": "CRxLAFPz9i-x",
        "outputId": "7da5ec01-cdcb-400d-d1dc-c4c4c73acb8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3661668509.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Prepare the predicted dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdataset_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdataset_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# your model's predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
          ]
        }
      ],
      "source": [
        "# Post-Processing\n",
        "# Postprocessing: Using Reject Option Classification for Equalized Odds\n",
        "from aif360.algorithms.postprocessing import RejectOptionClassification\n",
        "\n",
        "# Prepare the predicted dataset\n",
        "dataset_pred = dataset.copy()\n",
        "dataset_pred.labels = clf.predict(X_test)  # your model's predictions\n",
        "\n",
        "# Initialize RejectOptionClassification\n",
        "ROC = RejectOptionClassification(unprivileged_groups=[{'gender': 0}], privileged_groups=[{'gender': 1}])\n",
        "\n",
        "# Fit and adjust predictions\n",
        "roc_pred = ROC.fit_transform(dataset, dataset_pred)\n",
        "\n",
        "# Final predictions after postprocessing\n",
        "final_labels = roc_pred.labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mpjC2V4h9mwp",
      "metadata": {
        "id": "mpjC2V4h9mwp"
      },
      "source": [
        "To compare pros and cons of chosen methods, we can say:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46bebee8",
      "metadata": {
        "id": "46bebee8"
      },
      "source": [
        "Write down in text what you think the pros and cons are of the methods above"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Preprocessing Bias Mitigation: Reweighing vs. Optimized Preprocessing\n",
        "Pros of Reweighing:\n",
        "\n",
        "Simple to implement: Assigns weights to instances to balance protected groups.\n",
        "Model-agnostic: Works with any classifier supporting sample weights.\n",
        "Effective in many cases: Can reduce bias metrics like disparate impact and demographic parity.\n",
        "Cons of Reweighing:\n",
        "\n",
        "Does not directly optimize fairness: It only adjusts the importance of samples, not the classifier itself.\n",
        "Potential for increased variance: Heavily weighted samples can cause instability or overfitting.\n",
        "Limited to bias reduction: May not fully eliminate bias if data is highly imbalanced or complex.\n",
        "Pros of Optimized Preprocessing:\n",
        "\n",
        "Targeted bias mitigation: Uses learned transformations to directly reduce bias metrics.\n",
        "Potentially more effective: Can produce better fairness outcomes than simple reweighting.\n",
        "Direct control: Can optimize for specific fairness metrics.\n",
        "Cons of Optimized Preprocessing:\n",
        "\n",
        "Complex to implement: More involved, requiring tuning and complex algorithms.\n",
        "Computationally intensive: Requires additional optimization steps.\n",
        "May degrade predictive accuracy: As fairness is prioritized, accuracy may drop.\n",
        "2. In-processing Bias Mitigation: Meta Fair Classifier\n",
        "Pros:\n",
        "\n",
        "Fairness integrated during training: Adjusts model parameters to balance fairness and accuracy.\n",
        "Supports multiple fairness metrics: Can be tuned for different fairness goals.\n",
        "Model-agnostic to some extent: Can work with various classifiers if properly configured.\n",
        "Cons:\n",
        "\n",
        "Complex to implement: Requires specialized algorithms and hyperparameter tuning.\n",
        "Potential accuracy trade-offs: Improving fairness may slightly decrease prediction accuracy.\n",
        "Computationally demanding: Training can be slower due to fairness constraints.\n",
        "3. Postprocessing Bias Mitigation: Reject Option Classification (ROC) and Equalized Odds\n",
        "Pros:\n",
        "\n",
        "Flexible: Can be applied after model training, regardless of the initial model.\n",
        "Direct fairness improvement: Can explicitly enforce fairness constraints like Equalized Odds.\n",
        "Adjusts predictions: Can reject or modify predictions to meet fairness criteria.\n",
        "Cons:\n",
        "\n",
        "Potentially reduces accuracy: Rejecting or altering predictions may lower overall accuracy.\n",
        "Complex decision rules: Tuning rejection thresholds or fairness criteria can be complex.\n",
        "May impact usability: Rejecting predictions can lead to less actionable outputs if many are rejected."
      ],
      "metadata": {
        "id": "42WwPMz8QK2i"
      },
      "id": "42WwPMz8QK2i"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aibe_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}