{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"background-color: #004B87; padding: 20px; text-align: center; border-radius: 10px; color: white; font-family: Arial, sans-serif; margin: auto; width: 80%;\">\n",
        "    <h1>Module 3 Assignment</h1>\n",
        "    <h2>RURANGWA IRADUKUNDA Jean-François Régis</h2>\n",
        "    <h3>September 7, 2025</h3>\n",
        "    <p>Email : jeanfrancoisregis.rurangwairadukunda@axa.be</p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "xcKz6uU8Ce7X"
      },
      "id": "xcKz6uU8Ce7X"
    },
    {
      "cell_type": "markdown",
      "id": "516ee1d7-d4a0-4378-9a73-ff977fe061e6",
      "metadata": {
        "id": "516ee1d7-d4a0-4378-9a73-ff977fe061e6"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "\n",
        "Following the 'Actuarial Data Scientist' program offered by the Belgian association of actuaries (IABE), we are asked with an assignment that builds on the foundational concepts learned in the third and last module.\n",
        "<br/>\n",
        "This assignment involves analyzing the \"eusavingULnoPS\" dataset which is based on unit-linked saving products, with no profit sharing, sold in an unknown European country. Those insurance policies are observed between 1999 and 2008, with entries and exits possible.\n",
        "<br/>\n",
        "\n",
        "In this analysis, we will focus on developing classification and regression models for specific targets, applying feature selection techniques, and implementing explainability and fairness assessments.\n",
        "<br/>\n",
        "The objective is to provide actionable insights into the factors influencing policy lapses and risk premium proportions, ensuring the models are transparent, fair, and robust."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EUzqdV0xOgZZ",
      "metadata": {
        "id": "EUzqdV0xOgZZ"
      },
      "source": [
        "## Importing packages <a name=\"Importing_packages\"></a>\n",
        "\n",
        "Our first step is to import and load the packages that will be necessary in our task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "YuP6mnV0_mJi",
      "metadata": {
        "id": "YuP6mnV0_mJi",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4781df6a-3fab-4394-acad-7f59252306d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from shap) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shap) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shap) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Collecting shapicant\n",
            "  Downloading shapicant-0.4.0-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: shap>=0.36.0 in /usr/local/lib/python3.12/dist-packages (from shapicant) (0.48.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from shapicant) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from shapicant) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from shapicant) (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from shapicant) (4.67.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from shap>=0.36.0->shapicant) (1.16.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap>=0.36.0->shapicant) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap>=0.36.0->shapicant) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap>=0.36.0->shapicant) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap>=0.36.0->shapicant) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap>=0.36.0->shapicant) (4.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->shapicant) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->shapicant) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->shapicant) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shapicant) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->shapicant) (3.6.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap>=0.36.0->shapicant) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->shapicant) (1.17.0)\n",
            "Downloading shapicant-0.4.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: shapicant\n",
            "Successfully installed shapicant-0.4.0\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from scikeras) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from scikeras) (1.6.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from keras>=3.2.0->scikeras) (25.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from optree->keras>=3.2.0->scikeras) (4.15.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.2.0->scikeras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.13.0\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-3.3.2-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting mlflow-skinny==3.3.2 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.3.2-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.3.2 (from mlflow)\n",
            "  Downloading mlflow_tracing-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.5)\n",
            "Requirement already satisfied: cryptography<46,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<22,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.43)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (8.2.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (3.1.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.3.2->mlflow)\n",
            "  Downloading databricks_sdk-0.65.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (0.116.1)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (1.36.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (1.36.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (2.11.7)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.3.2->mlflow) (0.35.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<46,>=43.0.0->mlflow) (1.17.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<46,>=43.0.0->mlflow) (2.22)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (2.38.0)\n",
            "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.3.2->mlflow) (0.47.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.3.2->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.3.2->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.3.2->mlflow) (0.57b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.3.2->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.3.2->mlflow) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==3.3.2->mlflow) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.3.2->mlflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.3.2->mlflow) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.3.2->mlflow) (2025.8.3)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.3.2->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.3.2->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.3.2->mlflow) (4.10.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi<1->mlflow-skinny==3.3.2->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.3.2->mlflow) (0.6.1)\n",
            "Downloading mlflow-3.3.2-py3-none-any.whl (26.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.3.2-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.3.2-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.65.0-py3-none-any.whl (705 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.9/705.9 kB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: gunicorn, graphql-core, graphql-relay, docker, graphene, databricks-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
            "Successfully installed databricks-sdk-0.65.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.6 graphql-relay-3.2.0 gunicorn-23.0.0 mlflow-3.3.2 mlflow-skinny-3.3.2 mlflow-tracing-3.3.2\n",
            "Collecting evidently\n",
            "  Downloading evidently-0.7.14-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: plotly<6,>=5.10.0 in /usr/local/lib/python3.12/dist-packages (from evidently) (5.24.1)\n",
            "Requirement already satisfied: statsmodels>=0.12.2 in /usr/local/lib/python3.12/dist-packages (from evidently) (0.14.5)\n",
            "Requirement already satisfied: scikit-learn>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from evidently) (1.6.1)\n",
            "Requirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.12/dist-packages (from pandas[parquet]>=1.3.5->evidently) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.12/dist-packages (from evidently) (2.0.2)\n",
            "Requirement already satisfied: nltk>=3.6.7 in /usr/local/lib/python3.12/dist-packages (from evidently) (3.9.1)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from evidently) (1.16.1)\n",
            "Requirement already satisfied: requests>=2.32.0 in /usr/local/lib/python3.12/dist-packages (from evidently) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.12/dist-packages (from evidently) (6.0.2)\n",
            "Requirement already satisfied: pydantic>=1.10.16 in /usr/local/lib/python3.12/dist-packages (from evidently) (2.11.7)\n",
            "Collecting litestar>=2.8.3 (from evidently)\n",
            "  Downloading litestar-2.17.0-py3-none-any.whl.metadata (26 kB)\n",
            "Collecting typing-inspect>=0.9.0 (from evidently)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: uvicorn>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.22.0->evidently) (0.35.0)\n",
            "Requirement already satisfied: watchdog>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from evidently) (6.0.0)\n",
            "Requirement already satisfied: typer>=0.3 in /usr/local/lib/python3.12/dist-packages (from evidently) (0.17.3)\n",
            "Requirement already satisfied: rich>=13 in /usr/local/lib/python3.12/dist-packages (from evidently) (13.9.4)\n",
            "Collecting iterative-telemetry>=0.0.5 (from evidently)\n",
            "  Downloading iterative_telemetry-0.0.10-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting dynaconf>=3.2.4 (from evidently)\n",
            "  Downloading dynaconf-3.2.11-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from evidently) (2025.8.3)\n",
            "Requirement already satisfied: urllib3>=1.26.19 in /usr/local/lib/python3.12/dist-packages (from evidently) (2.5.0)\n",
            "Requirement already satisfied: fsspec>=2024.6.1 in /usr/local/lib/python3.12/dist-packages (from evidently) (2025.3.0)\n",
            "Collecting ujson>=5.4.0 (from evidently)\n",
            "  Downloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (9.4 kB)\n",
            "Collecting deprecation>=2.1.0 (from evidently)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting uuid6>=2024.7.10 (from evidently)\n",
            "  Downloading uuid6-2025.0.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.12/dist-packages (from evidently) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=43.0.1->evidently) (1.17.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from deprecation>=2.1.0->evidently) (25.0)\n",
            "Collecting appdirs (from iterative-telemetry>=0.0.5->evidently)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from iterative-telemetry>=0.0.5->evidently) (3.19.1)\n",
            "Requirement already satisfied: distro in /usr/local/lib/python3.12/dist-packages (from iterative-telemetry>=0.0.5->evidently) (1.9.0)\n",
            "Requirement already satisfied: anyio>=3 in /usr/local/lib/python3.12/dist-packages (from litestar>=2.8.3->evidently) (4.10.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from litestar>=2.8.3->evidently) (8.2.1)\n",
            "Requirement already satisfied: httpx>=0.22 in /usr/local/lib/python3.12/dist-packages (from litestar>=2.8.3->evidently) (0.28.1)\n",
            "Collecting litestar-htmx>=0.4.0 (from litestar>=2.8.3->evidently)\n",
            "  Downloading litestar_htmx-0.5.0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting msgspec>=0.18.2 (from litestar>=2.8.3->evidently)\n",
            "  Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: multidict>=6.0.2 in /usr/local/lib/python3.12/dist-packages (from litestar>=2.8.3->evidently) (6.6.4)\n",
            "Collecting multipart>=1.2.0 (from litestar>=2.8.3->evidently)\n",
            "  Downloading multipart-1.3.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting polyfactory>=2.6.3 (from litestar>=2.8.3->evidently)\n",
            "  Downloading polyfactory-2.22.2-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting rich-click (from litestar>=2.8.3->evidently)\n",
            "  Downloading rich_click-1.8.9-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from litestar>=2.8.3->evidently) (4.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.6.7->evidently) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.6.7->evidently) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.6.7->evidently) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.5->pandas[parquet]>=1.3.5->evidently) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.5->pandas[parquet]>=1.3.5->evidently) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.3.5->pandas[parquet]>=1.3.5->evidently) (2025.2)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from pandas[parquet]>=1.3.5->evidently) (18.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly<6,>=5.10.0->evidently) (8.5.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.16->evidently) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.16->evidently) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.10.16->evidently) (0.4.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->evidently) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.0->evidently) (3.10)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13->evidently) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13->evidently) (2.19.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.1->evidently) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.12.2->evidently) (1.0.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.3->evidently) (1.5.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.9.0->evidently)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn>=0.22.0->uvicorn[standard]>=0.22.0->evidently) (0.16.0)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.22.0->evidently)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.22.0->evidently) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.22.0->evidently)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.22.0->evidently)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.22.0->evidently) (15.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio>=3->litestar>=2.8.3->evidently) (1.3.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=43.0.1->evidently) (2.22)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.22->litestar>=2.8.3->evidently) (1.0.9)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13->evidently) (0.1.2)\n",
            "Collecting faker>=5.0.0 (from polyfactory>=2.6.3->litestar>=2.8.3->evidently)\n",
            "  Downloading faker-37.6.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->pandas[parquet]>=1.3.5->evidently) (1.17.0)\n",
            "Downloading evidently-0.7.14-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading dynaconf-3.2.11-py2.py3-none-any.whl (236 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.5/236.5 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading iterative_telemetry-0.0.10-py3-none-any.whl (10 kB)\n",
            "Downloading litestar-2.17.0-py3-none-any.whl (564 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading ujson-5.11.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uuid6-2025.0.1-py3-none-any.whl (7.0 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading litestar_htmx-0.5.0-py3-none-any.whl (10.0 kB)\n",
            "Downloading msgspec-0.19.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multipart-1.3.0-py3-none-any.whl (14 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Downloading polyfactory-2.22.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m57.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading rich_click-1.8.9-py3-none-any.whl (36 kB)\n",
            "Downloading faker-37.6.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, uvloop, uuid6, ujson, mypy-extensions, multipart, msgspec, litestar-htmx, httptools, faker, dynaconf, deprecation, watchfiles, typing-inspect, polyfactory, iterative-telemetry, rich-click, litestar, evidently\n",
            "Successfully installed appdirs-1.4.4 deprecation-2.1.0 dynaconf-3.2.11 evidently-0.7.14 faker-37.6.0 httptools-0.6.4 iterative-telemetry-0.0.10 litestar-2.17.0 litestar-htmx-0.5.0 msgspec-0.19.0 multipart-1.3.0 mypy-extensions-1.1.0 polyfactory-2.22.2 rich-click-1.8.9 typing-inspect-0.9.0 ujson-5.11.0 uuid6-2025.0.1 uvloop-0.21.0 watchfiles-1.1.0\n",
            "Collecting boruta\n",
            "  Downloading Boruta-0.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.12/dist-packages (from boruta) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.12/dist-packages (from boruta) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.12/dist-packages (from boruta) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.17.1->boruta) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.17.1->boruta) (3.6.0)\n",
            "Downloading Boruta-0.4.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: boruta\n",
            "Successfully installed boruta-0.4.3\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Collecting deap\n",
            "  Downloading deap-1.4.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading deap-1.4.3-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (135 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deap\n",
            "Successfully installed deap-1.4.3\n",
            "Collecting aif360\n",
            "  Downloading aif360-0.6.1-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.12/dist-packages (from aif360) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from aif360) (1.16.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from aif360) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.12/dist-packages (from aif360) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from aif360) (3.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->aif360) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->aif360) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=0.24.0->aif360) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->aif360) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0->aif360) (3.6.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->aif360) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.17.0)\n",
            "Downloading aif360-0.6.1-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.7/259.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: aif360\n",
            "Successfully installed aif360-0.6.1\n",
            "Cloning into 'Module-3-assignment'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 10 (delta 3), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (10/10), 727.56 KiB | 1.67 MiB/s, done.\n",
            "Resolving deltas: 100% (3/3), done.\n",
            "Collecting scikit-fuzzy\n",
            "  Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Downloading scikit_fuzzy-0.5.0-py2.py3-none-any.whl (920 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.8/920.8 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-fuzzy\n",
            "Successfully installed scikit-fuzzy-0.5.0\n"
          ]
        }
      ],
      "source": [
        "## Perform these pip installs in the command prompt, with your python kernel activated\n",
        "!pip install shap\n",
        "!pip install tensorflow\n",
        "!pip install shapicant\n",
        "!pip install scikeras\n",
        "!pip install mlflow\n",
        "!pip install evidently\n",
        "!pip install boruta\n",
        "!pip install pandas scikit-learn deap\n",
        "!pip install aif360\n",
        "\n",
        "!git clone https://github.com/Regis0323/Module-3-assignment.git\n",
        "!pip install scikit-fuzzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9b658fa8-eb1f-42b4-8178-42687d0f6f95",
      "metadata": {
        "id": "9b658fa8-eb1f-42b4-8178-42687d0f6f95",
        "tags": [],
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594ed68e-eaf1-469b-b909-3d5f0947cd8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# 1. SETUP: load libraries & data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Data preprocesing and models\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, RandomizedSearchCV\n",
        "from sklearn.linear_model import LassoCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "!pip install tensorflow\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "# MLFlow\n",
        "import mlflow\n",
        "import cloudpickle\n",
        "from evidently import Dataset\n",
        "from evidently import DataDefinition\n",
        "from evidently import Report\n",
        "from evidently.presets import DataDriftPreset, DataSummaryPreset\n",
        "\n",
        "# Feature selection and explainability of the model\n",
        "from mlxtend.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.inspection import permutation_importance\n",
        "from boruta import BorutaPy\n",
        "from deap import base, creator, tools, algorithms\n",
        "import random\n",
        "\n",
        "# Bias mitigation\n",
        "from aif360.datasets import StandardDataset, BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
        "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
        "from aif360.algorithms.preprocessing import Reweighing, OptimPreproc\n",
        "from aif360.algorithms.inprocessing import MetaFairClassifier, AdversarialDebiasing\n",
        "from aif360.algorithms.postprocessing import RejectOptionClassification, EqOddsPostprocessing\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2W8hGUD_Pb7q",
      "metadata": {
        "id": "2W8hGUD_Pb7q"
      },
      "source": [
        "# Data exploration and preoprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we load the dataset and get its specificities."
      ],
      "metadata": {
        "id": "Fix3fVKMTmvF"
      },
      "id": "Fix3fVKMTmvF"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "3f6e45e6-3c45-4ceb-8db7-130c4a5f9d2d",
      "metadata": {
        "id": "3f6e45e6-3c45-4ceb-8db7-130c4a5f9d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "outputId": "a5a29180-7aa9-4d57-bdf6-6ffbfdcd5369"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  policy.ID  issue.date termination.date lapse.reason premium.frequency  \\\n",
              "0        N1  1999-01-01       2006-04-01        Claim            unique   \n",
              "1        N2  1999-01-01       2006-04-01        Claim            unique   \n",
              "2        N3  1999-01-01       2005-04-01    Surrender            unique   \n",
              "3        N4  1999-01-01       2003-02-01    Surrender            unique   \n",
              "4        N5  1999-01-01       2008-01-01     In force            unique   \n",
              "\n",
              "   gender  underwriting.age  face.amount  risk.premium  saving.premium  ...  \\\n",
              "0    Male                77      2979.53        265.86        29795.27  ...   \n",
              "1    Male                77      3039.71        271.23        30397.16  ...   \n",
              "2  Female                72      2994.12         80.43        35929.44  ...   \n",
              "3    Male                35      3051.10          7.50        30511.01  ...   \n",
              "4    Male                40      5810.21         81.39        58102.11  ...   \n",
              "\n",
              "   rate2Y.relvar1mth  rate2Y.relvar1qtr  rate10Y.relvar1mth  \\\n",
              "0           0.086310           0.184211            0.081598   \n",
              "1           0.086310           0.184211            0.081598   \n",
              "2          -0.025391          -0.018489           -0.023343   \n",
              "3          -0.041762          -0.133838           -0.038309   \n",
              "4           0.037712          -0.004430            0.025938   \n",
              "\n",
              "   rate10Y.relvar1qtr  unemploy.relvar1mth  unemploy.relvar1qtr  \\\n",
              "0            0.144626            -0.011494            -0.011494   \n",
              "1            0.144626            -0.011494            -0.011494   \n",
              "2           -0.018868            -0.010309            -0.040816   \n",
              "3           -0.039273             0.000000            -0.008850   \n",
              "4           -0.002027             0.022727             0.069767   \n",
              "\n",
              "   industry.relvar1mth  industry.relvar1qtr  RTV.relvar1mth  RTV.relvar1qtr  \n",
              "0            -0.000979             0.016699        0.005941        0.006931  \n",
              "1            -0.000979             0.016699        0.005941        0.006931  \n",
              "2             0.001000             0.003024        0.002002        0.000998  \n",
              "3            -0.003067             0.000000        0.009524        0.009574  \n",
              "4             0.001876             0.000941       -0.011550       -0.026692  \n",
              "\n",
              "[5 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99b646ce-5683-40d5-a922-b87807fc55cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>policy.ID</th>\n",
              "      <th>issue.date</th>\n",
              "      <th>termination.date</th>\n",
              "      <th>lapse.reason</th>\n",
              "      <th>premium.frequency</th>\n",
              "      <th>gender</th>\n",
              "      <th>underwriting.age</th>\n",
              "      <th>face.amount</th>\n",
              "      <th>risk.premium</th>\n",
              "      <th>saving.premium</th>\n",
              "      <th>...</th>\n",
              "      <th>rate2Y.relvar1mth</th>\n",
              "      <th>rate2Y.relvar1qtr</th>\n",
              "      <th>rate10Y.relvar1mth</th>\n",
              "      <th>rate10Y.relvar1qtr</th>\n",
              "      <th>unemploy.relvar1mth</th>\n",
              "      <th>unemploy.relvar1qtr</th>\n",
              "      <th>industry.relvar1mth</th>\n",
              "      <th>industry.relvar1qtr</th>\n",
              "      <th>RTV.relvar1mth</th>\n",
              "      <th>RTV.relvar1qtr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N1</td>\n",
              "      <td>1999-01-01</td>\n",
              "      <td>2006-04-01</td>\n",
              "      <td>Claim</td>\n",
              "      <td>unique</td>\n",
              "      <td>Male</td>\n",
              "      <td>77</td>\n",
              "      <td>2979.53</td>\n",
              "      <td>265.86</td>\n",
              "      <td>29795.27</td>\n",
              "      <td>...</td>\n",
              "      <td>0.086310</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>0.081598</td>\n",
              "      <td>0.144626</td>\n",
              "      <td>-0.011494</td>\n",
              "      <td>-0.011494</td>\n",
              "      <td>-0.000979</td>\n",
              "      <td>0.016699</td>\n",
              "      <td>0.005941</td>\n",
              "      <td>0.006931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N2</td>\n",
              "      <td>1999-01-01</td>\n",
              "      <td>2006-04-01</td>\n",
              "      <td>Claim</td>\n",
              "      <td>unique</td>\n",
              "      <td>Male</td>\n",
              "      <td>77</td>\n",
              "      <td>3039.71</td>\n",
              "      <td>271.23</td>\n",
              "      <td>30397.16</td>\n",
              "      <td>...</td>\n",
              "      <td>0.086310</td>\n",
              "      <td>0.184211</td>\n",
              "      <td>0.081598</td>\n",
              "      <td>0.144626</td>\n",
              "      <td>-0.011494</td>\n",
              "      <td>-0.011494</td>\n",
              "      <td>-0.000979</td>\n",
              "      <td>0.016699</td>\n",
              "      <td>0.005941</td>\n",
              "      <td>0.006931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>N3</td>\n",
              "      <td>1999-01-01</td>\n",
              "      <td>2005-04-01</td>\n",
              "      <td>Surrender</td>\n",
              "      <td>unique</td>\n",
              "      <td>Female</td>\n",
              "      <td>72</td>\n",
              "      <td>2994.12</td>\n",
              "      <td>80.43</td>\n",
              "      <td>35929.44</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.025391</td>\n",
              "      <td>-0.018489</td>\n",
              "      <td>-0.023343</td>\n",
              "      <td>-0.018868</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>-0.040816</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.003024</td>\n",
              "      <td>0.002002</td>\n",
              "      <td>0.000998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>N4</td>\n",
              "      <td>1999-01-01</td>\n",
              "      <td>2003-02-01</td>\n",
              "      <td>Surrender</td>\n",
              "      <td>unique</td>\n",
              "      <td>Male</td>\n",
              "      <td>35</td>\n",
              "      <td>3051.10</td>\n",
              "      <td>7.50</td>\n",
              "      <td>30511.01</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.041762</td>\n",
              "      <td>-0.133838</td>\n",
              "      <td>-0.038309</td>\n",
              "      <td>-0.039273</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.008850</td>\n",
              "      <td>-0.003067</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009524</td>\n",
              "      <td>0.009574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>N5</td>\n",
              "      <td>1999-01-01</td>\n",
              "      <td>2008-01-01</td>\n",
              "      <td>In force</td>\n",
              "      <td>unique</td>\n",
              "      <td>Male</td>\n",
              "      <td>40</td>\n",
              "      <td>5810.21</td>\n",
              "      <td>81.39</td>\n",
              "      <td>58102.11</td>\n",
              "      <td>...</td>\n",
              "      <td>0.037712</td>\n",
              "      <td>-0.004430</td>\n",
              "      <td>0.025938</td>\n",
              "      <td>-0.002027</td>\n",
              "      <td>0.022727</td>\n",
              "      <td>0.069767</td>\n",
              "      <td>0.001876</td>\n",
              "      <td>0.000941</td>\n",
              "      <td>-0.011550</td>\n",
              "      <td>-0.026692</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 30 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99b646ce-5683-40d5-a922-b87807fc55cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-99b646ce-5683-40d5-a922-b87807fc55cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-99b646ce-5683-40d5-a922-b87807fc55cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-89ea3345-f874-46c8-9093-566d10b13c1e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89ea3345-f874-46c8-9093-566d10b13c1e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-89ea3345-f874-46c8-9093-566d10b13c1e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64    23\n",
            "object      6\n",
            "int64       1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Load\n",
        "df = pd.read_csv(\"/content/Module-3-assignment/eusavingULnoPS.csv\")\n",
        "display(df.head())\n",
        "print(df.dtypes.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "k9dGsrG-axlE",
      "metadata": {
        "id": "k9dGsrG-axlE"
      },
      "source": [
        "Our dataset is composed of 30 columns, of which 6 are categorized as 'object', 1 as 64-bit 'integer' (int64) and 23 as 64-bit 'floating-point' (float64) numbers.\n",
        "<br>\n",
        "We shall now check for missing and/or duplicated values before treating them accordingly if any."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "r24UfL7G7M7e",
      "metadata": {
        "id": "r24UfL7G7M7e",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1f2e909-4def-493c-e2ce-e23ff55afcd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "policy.ID              0\n",
            "issue.date             0\n",
            "termination.date       0\n",
            "lapse.reason           0\n",
            "premium.frequency      0\n",
            "gender                 0\n",
            "underwriting.age       0\n",
            "face.amount            0\n",
            "risk.premium           0\n",
            "saving.premium         0\n",
            "CPI.relvar1mth         0\n",
            "CPI.relvar1qtr         0\n",
            "CPI.relvar1yr          0\n",
            "CPI.relvar2yr          0\n",
            "EUidx.relvar1mth       0\n",
            "EUidx.relvar1qtr       0\n",
            "EUidx.relvar1yr        0\n",
            "EUidx.relvar2yr        0\n",
            "rate1Y.relvar1mth      0\n",
            "rate1Y.relvar1qtr      0\n",
            "rate2Y.relvar1mth      0\n",
            "rate2Y.relvar1qtr      0\n",
            "rate10Y.relvar1mth     0\n",
            "rate10Y.relvar1qtr     0\n",
            "unemploy.relvar1mth    0\n",
            "unemploy.relvar1qtr    0\n",
            "industry.relvar1mth    0\n",
            "industry.relvar1qtr    0\n",
            "RTV.relvar1mth         0\n",
            "RTV.relvar1qtr         0\n",
            "dtype: int64\n",
            "Empty DataFrame\n",
            "Columns: [policy.ID, issue.date, termination.date, lapse.reason, premium.frequency, gender, underwriting.age, face.amount, risk.premium, saving.premium, CPI.relvar1mth, CPI.relvar1qtr, CPI.relvar1yr, CPI.relvar2yr, EUidx.relvar1mth, EUidx.relvar1qtr, EUidx.relvar1yr, EUidx.relvar2yr, rate1Y.relvar1mth, rate1Y.relvar1qtr, rate2Y.relvar1mth, rate2Y.relvar1qtr, rate10Y.relvar1mth, rate10Y.relvar1qtr, unemploy.relvar1mth, unemploy.relvar1qtr, industry.relvar1mth, industry.relvar1qtr, RTV.relvar1mth, RTV.relvar1qtr]\n",
            "Index: []\n",
            "\n",
            "[0 rows x 30 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 21921 entries, 0 to 21920\n",
            "Data columns (total 30 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   policy.ID            21921 non-null  object \n",
            " 1   issue.date           21921 non-null  object \n",
            " 2   termination.date     21921 non-null  object \n",
            " 3   lapse.reason         21921 non-null  object \n",
            " 4   premium.frequency    21921 non-null  object \n",
            " 5   gender               21921 non-null  object \n",
            " 6   underwriting.age     21921 non-null  int64  \n",
            " 7   face.amount          21921 non-null  float64\n",
            " 8   risk.premium         21921 non-null  float64\n",
            " 9   saving.premium       21921 non-null  float64\n",
            " 10  CPI.relvar1mth       21921 non-null  float64\n",
            " 11  CPI.relvar1qtr       21921 non-null  float64\n",
            " 12  CPI.relvar1yr        21921 non-null  float64\n",
            " 13  CPI.relvar2yr        21921 non-null  float64\n",
            " 14  EUidx.relvar1mth     21921 non-null  float64\n",
            " 15  EUidx.relvar1qtr     21921 non-null  float64\n",
            " 16  EUidx.relvar1yr      21921 non-null  float64\n",
            " 17  EUidx.relvar2yr      21921 non-null  float64\n",
            " 18  rate1Y.relvar1mth    21921 non-null  float64\n",
            " 19  rate1Y.relvar1qtr    21921 non-null  float64\n",
            " 20  rate2Y.relvar1mth    21921 non-null  float64\n",
            " 21  rate2Y.relvar1qtr    21921 non-null  float64\n",
            " 22  rate10Y.relvar1mth   21921 non-null  float64\n",
            " 23  rate10Y.relvar1qtr   21921 non-null  float64\n",
            " 24  unemploy.relvar1mth  21921 non-null  float64\n",
            " 25  unemploy.relvar1qtr  21921 non-null  float64\n",
            " 26  industry.relvar1mth  21921 non-null  float64\n",
            " 27  industry.relvar1qtr  21921 non-null  float64\n",
            " 28  RTV.relvar1mth       21921 non-null  float64\n",
            " 29  RTV.relvar1qtr       21921 non-null  float64\n",
            "dtypes: float64(23), int64(1), object(6)\n",
            "memory usage: 5.0+ MB\n",
            "['policy.ID', 'issue.date', 'termination.date', 'lapse.reason', 'premium.frequency', 'gender', 'underwriting.age', 'face.amount', 'risk.premium', 'saving.premium', 'CPI.relvar1mth', 'CPI.relvar1qtr', 'CPI.relvar1yr', 'CPI.relvar2yr', 'EUidx.relvar1mth', 'EUidx.relvar1qtr', 'EUidx.relvar1yr', 'EUidx.relvar2yr', 'rate1Y.relvar1mth', 'rate1Y.relvar1qtr', 'rate2Y.relvar1mth', 'rate2Y.relvar1qtr', 'rate10Y.relvar1mth', 'rate10Y.relvar1qtr', 'unemploy.relvar1mth', 'unemploy.relvar1qtr', 'industry.relvar1mth', 'industry.relvar1qtr', 'RTV.relvar1mth', 'RTV.relvar1qtr']\n"
          ]
        }
      ],
      "source": [
        "#Potential missing values\n",
        "Missing_Values=df.isna().sum()\n",
        "print(Missing_Values)\n",
        "\n",
        "#Potential duplicated values\n",
        "Duplicated_Values=df[df.duplicated(keep=False)]\n",
        "print(Duplicated_Values)\n",
        "  #Treating duplicated values (if any)\n",
        "df_cleaned=df.drop_duplicates(keep='first')\n",
        "\n",
        "#Information about the new cleaned dataset\n",
        "df_cleaned.info()\n",
        "print(df_cleaned.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "099I_dd4bD61",
      "metadata": {
        "id": "099I_dd4bD61"
      },
      "source": [
        "After this check, we can see that there are neither missing values nor duplicates and there are 2 date variables that have been properly treated.\n",
        "\n",
        "We shall now create two datasets (df_cat and df_num), one for each of the following two dependent variables:\n",
        "*   a categorical one: lapse.reason;\n",
        "*   a numeric one: a numerical variable that represents the proportion of risk premium over total premium: proportion_risk_premium = risk.premium / (risk.premium+saving.premium)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "xlLmk_Rsx7vc",
      "metadata": {
        "id": "xlLmk_Rsx7vc"
      },
      "outputs": [],
      "source": [
        "# Conversion of the date columns from 'object' to 'datetime'\n",
        "df_cleaned['issue.date'] = pd.to_datetime(df['issue.date'], errors='coerce')\n",
        "df_cleaned['termination.date'] = pd.to_datetime(df['termination.date'], errors='coerce')\n",
        "\n",
        "# Creation of numerical and categorical datasets\n",
        "df_cat = df_cleaned.copy()\n",
        "df_num = df_cleaned.copy()\n",
        "\n",
        "# Creation of numerical dependent variable\n",
        "df_num['proportion_risk_premium'] = df_num['risk.premium']/(df_num['risk.premium'] + df_num['saving.premium'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XZ5Mhh5DbJ9c",
      "metadata": {
        "id": "XZ5Mhh5DbJ9c"
      },
      "source": [
        "## Data preprocessing\n",
        "After creating the numerical and categorical datasets, we shall now define the X (X_cat and X_num) and y datasets before converting categorical variables to a suitable format (using the \"one-hot encoding\" method), handling date variables and splitting the datasets into training and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "kxMkhp8KQ01J",
      "metadata": {
        "id": "kxMkhp8KQ01J"
      },
      "outputs": [],
      "source": [
        "# Define X and y (wisely select variables for the X datasets)\n",
        "y_num = df_num['proportion_risk_premium']\n",
        "y_cat = df_cat['lapse.reason']\n",
        "X_num = df_num.drop(['proportion_risk_premium'], axis=1)\n",
        "X_cat = df_cat.drop(['lapse.reason'], axis=1)\n",
        "\n",
        "# One-hot encoding method for categorical variables\n",
        "categorical_cols = X_cat.select_dtypes(include=['object']).columns.tolist()\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_cols)],\n",
        "    remainder='passthrough')\n",
        "\n",
        "# Example on how to handle date variables\n",
        "for df_ in [X_num, X_cat]:\n",
        "    df_['issue_date_year'] = df_['issue.date'].dt.year\n",
        "    df_['issue_date_month'] = df_['issue.date'].dt.month\n",
        "    df_['termination_date_year'] = df_['termination.date'].dt.year\n",
        "    df_['termination_date_month'] = df_['termination.date'].dt.month\n",
        "    df_.drop(['issue.date', 'termination.date'], axis=1, inplace=True)\n",
        "\n",
        "# Split test and train datasets\n",
        "X_train_cat, X_test_cat, y_train_cat, y_test_cat = train_test_split(X_cat, y_cat, test_size=0.25, random_state=23, stratify=y_cat)\n",
        "\n",
        "X_train_num, X_test_num, y_train_num, y_test_num = train_test_split(X_num, y_num, test_size=0.25, random_state=23)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XI885gZbJ3Sr",
      "metadata": {
        "id": "XI885gZbJ3Sr"
      },
      "source": [
        "## Development of model for categorical variable: RandomForest\n",
        "\n",
        "In this part we shall develop a Random Forest algorithm for the categorical dependent variable \"lapse.reason\"."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the pipeline with preprocessing and classifier\n",
        "rf_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),  # Your existing OneHotEncoder + passthrough\n",
        "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=23))\n",
        "])\n",
        "\n",
        "# Fit the model on training data\n",
        "rf_pipeline.fit(X_train_cat, y_train_cat)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = rf_pipeline.predict(X_test_cat)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Classification report for 'lapse.reason':\")\n",
        "print(classification_report(y_test_cat, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezPnnDZOR33z",
        "outputId": "c75bd2f4-e4e2-4c2a-bc80-b572a7b18814"
      },
      "id": "ezPnnDZOR33z",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification report for 'lapse.reason':\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Claim       1.00      0.10      0.19        49\n",
            "    In force       1.00      1.00      1.00      3470\n",
            "   Surrender       0.98      1.00      0.99      1962\n",
            "\n",
            "    accuracy                           0.99      5481\n",
            "   macro avg       0.99      0.70      0.72      5481\n",
            "weighted avg       0.99      0.99      0.99      5481\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summary:\n",
        "The current model is performing well overall, but poorly on the minority class.\n",
        "Tuning can help improve recall for 'Claim'.\n",
        "So, yes, you should tune and experiment further."
      ],
      "metadata": {
        "id": "9zeCBbI3TVk-"
      },
      "id": "9zeCBbI3TVk-"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "ueOE244D57fa",
      "metadata": {
        "id": "ueOE244D57fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "5d70b21d-c9cd-4d1e-de40-76a383b87a19"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'X_train_cat' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3079890609.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 1. Encode categorical variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcategorical_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train_cat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m preprocessor = ColumnTransformer(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train_cat' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# 1. Encode categorical variables\n",
        "categorical_cols = X_train_cat.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit and transform training data\n",
        "X_train_encoded = preprocessor.fit_transform(X_train_cat)\n",
        "\n",
        "# 2. Apply SMOTE on the encoded data\n",
        "smote = SMOTE(random_state=23)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_encoded, y_train_cat)\n",
        "\n",
        "# 3. Now, X_resampled is fully numerical and balanced\n",
        "# You can train your model directly on X_resampled, y_resampled\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure imbalanced-learn is installed\n",
        "!pip install imbalanced-learn\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, precision_recall_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- Step 1: Encode your categorical features ---\n",
        "# Use your existing 'preprocessor' for encoding\n",
        "X_train_encoded = preprocessor.fit_transform(X_train_cat)\n",
        "X_test_encoded = preprocessor.transform(X_test_cat)\n",
        "\n",
        "# --- Step 2: Apply SMOTE to balance the training data ---\n",
        "smote = SMOTE(random_state=23)\n",
        "X_resampled, y_resampled = smote.fit_resample(X_train_encoded, y_train_cat)\n",
        "\n",
        "# --- Step 3: Build a pipeline with best hyperparameters and class_weight='balanced' ---\n",
        "best_params = {\n",
        "    'classifier__n_estimators': 100,\n",
        "    'classifier__min_samples_split': 2,\n",
        "    'classifier__min_samples_leaf': 1,\n",
        "    'classifier__max_features': 'log2',\n",
        "    'classifier__max_depth': None\n",
        "}\n",
        "\n",
        "clf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', RandomForestClassifier(**best_params, class_weight='balanced', random_state=23))\n",
        "])\n",
        "\n",
        "# --- Step 4: Train on the SMOTE-balanced data ---\n",
        "clf.fit(X_resampled, y_resampled)\n",
        "\n",
        "# --- Step 5: Get probabilities on test set ---\n",
        "y_proba = clf.predict_proba(X_test_encoded)\n",
        "\n",
        "# Find index of 'Claim'\n",
        "claim_idx = list(clf.named_steps['classifier'].classes_).index('Claim')\n",
        "claim_probs = y_proba[:, claim_idx]\n",
        "\n",
        "# --- Step 6: Plot Precision-Recall curve ---\n",
        "precision, recall, thresholds = precision_recall_curve(y_test == 'Claim', claim_probs)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(thresholds, precision[:-1], label='Precision')\n",
        "plt.plot(thresholds, recall[:-1], label='Recall')\n",
        "plt.xlabel('Decision Threshold')\n",
        "plt.title('Precision-Recall Trade-off for Claim Class')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# --- Step 7: Select an optimal threshold (e.g., 0.05) to improve recall ---\n",
        "optimal_threshold = 0.05\n",
        "y_pred_adjusted = (claim_probs >= optimal_threshold).astype(str)\n",
        "\n",
        "# --- Step 8: Evaluate at this threshold ---\n",
        "print(f\"Classification report at threshold={optimal_threshold}:\")\n",
        "print(classification_report(y_test_cat, y_pred_adjusted))\n"
      ],
      "metadata": {
        "id": "du6TlYyQW-mp",
        "outputId": "6200d3eb-ee98-4eef-c3c4-4879e80e0374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "id": "du6TlYyQW-mp",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: numpy<3,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.11.4 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'preprocessor' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-827607487.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# --- Step 1: Encode your categorical features ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Use your existing 'preprocessor' for encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mX_train_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mX_test_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_cat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'preprocessor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_dist = {\n",
        "    'classifier__n_estimators': [50, 100, 200],\n",
        "    'classifier__max_depth': [None, 10, 20],\n",
        "    'classifier__min_samples_split': [2, 5, 10],\n",
        "    'classifier__min_samples_leaf': [1, 2, 4],\n",
        "    'classifier__max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Set up RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    rf_pipeline, param_distributions=param_dist,\n",
        "    n_iter=20, scoring='f1_weighted', cv=5, n_jobs=-1, verbose=2, random_state=23\n",
        ")\n",
        "\n",
        "# Run hyperparameter tuning\n",
        "random_search.fit(X_train_cat, y_train_cat)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best hyperparameters:\", random_search.best_params_)\n",
        "\n",
        "# Evaluate the best model\n",
        "best_model = random_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_cat)\n",
        "print(\"Classification report after hyperparameter tuning:\")\n",
        "print(classification_report(y_test_cat, y_pred))\n"
      ],
      "metadata": {
        "id": "EhgPkMb7TtyM",
        "outputId": "10a7ba97-7e95-4c8e-c725-8a0f62b7cbe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "EhgPkMb7TtyM",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Best hyperparameters: {'classifier__n_estimators': 100, 'classifier__min_samples_split': 2, 'classifier__min_samples_leaf': 1, 'classifier__max_features': 'log2', 'classifier__max_depth': None}\n",
            "Classification report after hyperparameter tuning:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Claim       1.00      0.10      0.19        49\n",
            "    In force       1.00      1.00      1.00      3470\n",
            "   Surrender       0.98      1.00      0.99      1962\n",
            "\n",
            "    accuracy                           0.99      5481\n",
            "   macro avg       0.99      0.70      0.72      5481\n",
            "weighted avg       0.99      0.99      0.99      5481\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Bc1ljHyeKQCj",
      "metadata": {
        "id": "Bc1ljHyeKQCj"
      },
      "source": [
        "## Development of model for numerical variable (proportion): Sequential Dense NN\n",
        "\n",
        "\n",
        "For the numerical variable \"proportion_risk_premium\", develop a Sequential Dense Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4_-XSP6_58ah",
      "metadata": {
        "id": "4_-XSP6_58ah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3284f02-3490-49e9-a90c-2670bce975df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.7012e-07 - mae: 3.2976e-04\n",
            "Test MAE for risk proportion: 0.00033756138873286545\n"
          ]
        }
      ],
      "source": [
        "scaler_num = StandardScaler()\n",
        "# Normalize numerical features\n",
        "X_train_num_scaled = scaler_num.fit_transform(X_train_num)\n",
        "X_test_num_scaled = scaler_num.transform(X_test_num)\n",
        "\n",
        "# Define neural network\n",
        "model = models.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=(X_train_num_scaled.shape[1],)),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train with early stopping\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "model.fit(\n",
        "    X_train_num_scaled,\n",
        "    y_train_num,\n",
        "    validation_split=0.2,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "# Evaluate\n",
        "loss, mae = model.evaluate(X_test_num_scaled, y_test_num)\n",
        "print(f\"Test MAE for risk proportion: {mae}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8RSD2zs9TRUh",
      "metadata": {
        "id": "8RSD2zs9TRUh"
      },
      "source": [
        "# Variable selection"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FlXxBhvuFhfS",
      "metadata": {
        "id": "FlXxBhvuFhfS"
      },
      "source": [
        "## Categorical problem, feature selection\n",
        "\n",
        "\n",
        "For the categorical dependent variable \"lapse.reason\", perform Boruta feature selection using (from boruta) BortutaPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "VlXLu31W5snq",
      "metadata": {
        "id": "VlXLu31W5snq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "53e3624f-3259-42f7-e9cc-97b547fb5c7e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Sparse data was passed for X, but dense data is required. Use '.toarray()' to convert to a dense numpy array.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-502311826.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# Run Boruta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mboruta_selector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBorutaPy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_for_boruta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m23\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mboruta_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_cat_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_boruta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Get selected feature indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/boruta/boruta_py.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \"\"\"\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/boruta/boruta_py.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;31m# check input params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/boruta/boruta_py.py\u001b[0m in \u001b[0;36m_check_params\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    606\u001b[0m         \"\"\"\n\u001b[1;32m    607\u001b[0m         \u001b[0;31m# check X and y are consistent len, X is Array and y is column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperc\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperc\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The percentile should be between 0 and 100.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0m_ensure_no_complex_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m         array = _ensure_sparse_format(\n\u001b[0m\u001b[1;32m   1015\u001b[0m             \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[0;34m(sparse_container, accept_sparse, dtype, copy, ensure_all_finite, accept_large_sparse, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0mpadded_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" for \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_name\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 613\u001b[0;31m         raise TypeError(\n\u001b[0m\u001b[1;32m    614\u001b[0m             \u001b[0;34mf\"Sparse data was passed{padded_input}, but dense data is required. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m             \u001b[0;34m\"Use '.toarray()' to convert to a dense numpy array.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Sparse data was passed for X, but dense data is required. Use '.toarray()' to convert to a dense numpy array."
          ]
        }
      ],
      "source": [
        "categorical_features = list(X_train_cat.select_dtypes(include=['object']).columns)\n",
        "\n",
        "# Create the preprocessor with sparse output\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit and transform (sparse output)\n",
        "X_train_cat_encoded = preprocessor.fit_transform(X_train_cat)\n",
        "\n",
        "# No need to convert to dense\n",
        "# Use BorutaPy directly with sparse matrix\n",
        "rf_for_boruta = RandomForestClassifier(n_estimators=100, random_state=23)\n",
        "\n",
        "# Encode y\n",
        "le = LabelEncoder()\n",
        "y_boruta = le.fit_transform(y_train_cat)\n",
        "\n",
        "# Run Boruta\n",
        "boruta_selector = BorutaPy(rf_for_boruta, max_iter=50, random_state=23)\n",
        "boruta_selector.fit(X_train_cat_encoded, y_boruta)\n",
        "\n",
        "# Get selected feature indices\n",
        "support_mask = boruta_selector.support_\n",
        "\n",
        "# Get feature names from the OneHotEncoder\n",
        "feature_names = preprocessor.get_feature_names_out(categorical_features)\n",
        "selected_features_boruta = feature_names[support_mask]\n",
        "print(\"Boruta selected features:\", list(selected_features_boruta))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HMDLAYd75uph",
      "metadata": {
        "id": "HMDLAYd75uph"
      },
      "source": [
        "For the categorical dependent variable \"lapse.reason\", perform Genetic Algorith feature selection using (from deap) base, creator, tools, algorithms repspectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sY9sH1S95zke",
      "metadata": {
        "id": "sY9sH1S95zke"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "bw6yKyYf8dx6",
      "metadata": {
        "id": "bw6yKyYf8dx6"
      },
      "source": [
        "Optional: Use MLFLow to show you know how to use good development and tracking practices while training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prkWG2CWAPOx",
      "metadata": {
        "id": "prkWG2CWAPOx"
      },
      "outputs": [],
      "source": [
        "# Setup MLFlow\n",
        "\n",
        "host =\n",
        "port =\n",
        "mlflow.set_tracking_uri(uri=f\"http://{host}:{port}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D9G0By67EGZj",
      "metadata": {
        "id": "D9G0By67EGZj"
      },
      "outputs": [],
      "source": [
        "# Model packaging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "sTH_5RwoEHr7",
      "metadata": {
        "id": "sTH_5RwoEHr7"
      },
      "outputs": [],
      "source": [
        "# Model registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JhpSOrm4EJiL",
      "metadata": {
        "id": "JhpSOrm4EJiL"
      },
      "outputs": [],
      "source": [
        "# Model serving\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fkLNd6bEKxM",
      "metadata": {
        "id": "8fkLNd6bEKxM"
      },
      "outputs": [],
      "source": [
        "# Model monitoring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70jdGydFFon-",
      "metadata": {
        "id": "70jdGydFFon-"
      },
      "source": [
        "## Numerical problem, feature selection\n",
        "\n",
        "For the numerical variable \"proportion_risk_premium\", perform a forward and a backward selection on explanatory variables.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "lltiuzAZyXWt",
      "metadata": {
        "id": "lltiuzAZyXWt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "ac93c736-e33c-4b6a-dbc0-2dad19ffcb6d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'scaler_num' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2972445575.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Standardize features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_num_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler_num\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Forward selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m sfs_forward = SequentialFeatureSelector(\n",
            "\u001b[0;31mNameError\u001b[0m: name 'scaler_num' is not defined"
          ]
        }
      ],
      "source": [
        "# Standardize features\n",
        "X_train_num_scaled = scaler_num.fit_transform(X_train_num)\n",
        "\n",
        "# Forward selection\n",
        "sfs_forward = SequentialFeatureSelector(\n",
        "    Lasso(alpha=0.01),\n",
        "    n_features_to_select=10,\n",
        "    direction='forward'\n",
        ")\n",
        "sfs_forward.fit(X_train_num_scaled, y_train_num)\n",
        "print(\"Forward selection features:\", X_train_num.columns[sfs_forward.get_support()])\n",
        "\n",
        "# Backward selection\n",
        "sfs_backward = SequentialFeatureSelector(\n",
        "    Lasso(alpha=0.01),\n",
        "    n_features_to_select=10,\n",
        "    direction='backward'\n",
        ")\n",
        "sfs_backward.fit(X_train_num_scaled, y_train_num)\n",
        "print(\"Backward selection features:\", X_train_num.columns[sfs_backward.get_support()])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BJlJAwZQ6_pO",
      "metadata": {
        "id": "BJlJAwZQ6_pO"
      },
      "source": [
        "For the numerical variable \"proportion_risk_premium\", apply Lasso using LassoCV."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IOfqUffz7ATL",
      "metadata": {
        "id": "IOfqUffz7ATL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "btavk4CC8gY7",
      "metadata": {
        "id": "btavk4CC8gY7"
      },
      "source": [
        "Optional: Use MLFLow to show you know how to use good development and tracking practices while training the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "pAlEDL6KETnH",
      "metadata": {
        "id": "pAlEDL6KETnH"
      },
      "outputs": [],
      "source": [
        "# Setup MLFlow\n",
        "\n",
        "host =\n",
        "port =\n",
        "mlflow.set_tracking_uri(uri=f\"http://{host}:{port}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2syae_30ETnH",
      "metadata": {
        "id": "2syae_30ETnH"
      },
      "outputs": [],
      "source": [
        "# Model packaging\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "V7vIRIbPETnI",
      "metadata": {
        "id": "V7vIRIbPETnI"
      },
      "outputs": [],
      "source": [
        "# Model registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8iIYeY_QETnI",
      "metadata": {
        "id": "8iIYeY_QETnI"
      },
      "outputs": [],
      "source": [
        "# Model serving\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "76Zydou-ETnI",
      "metadata": {
        "id": "76Zydou-ETnI"
      },
      "outputs": [],
      "source": [
        "# Model monitoring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TDgCQsykrs_5",
      "metadata": {
        "id": "TDgCQsykrs_5"
      },
      "source": [
        "# Explainability of the model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e_UZkcj2rw89",
      "metadata": {
        "id": "e_UZkcj2rw89"
      },
      "source": [
        "## Categorical problem\n",
        "\n",
        "Explain the RandomForest model to a client, that wants to know why their quote is so high by permutation feature selection using permutation_importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "918Qi51_5reD",
      "metadata": {
        "id": "918Qi51_5reD"
      },
      "outputs": [],
      "source": [
        "result = permutation_importance(clf_cat, X_test_cat, y_test_cat, n_repeats=10, random_state=42)\n",
        "importances = pd.Series(result.importances_mean, index=X_test_cat.columns)\n",
        "print(\"Feature importances:\\n\", importances.sort_values(ascending=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ogt_2Kv9GF6",
      "metadata": {
        "id": "6ogt_2Kv9GF6"
      },
      "source": [
        "Choose another method of your preference to explain the RandomForest model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jxe13YHE9LCB",
      "metadata": {
        "id": "Jxe13YHE9LCB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "eS87my6hx_3N",
      "metadata": {
        "id": "eS87my6hx_3N"
      },
      "source": [
        "## Numerical problem"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Eh90ACcpr4XT",
      "metadata": {
        "id": "Eh90ACcpr4XT"
      },
      "source": [
        "Explain the Neural Netwok model to a client, that wants to know why their quote is so high using Shapley values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JnoUoZFb5rDv",
      "metadata": {
        "id": "JnoUoZFb5rDv"
      },
      "outputs": [],
      "source": [
        "X_sample = X_test_num_scaled[:100]\n",
        "explainer = shap.KernelExplainer(model.predict, X_train_num_scaled[:100])\n",
        "shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "shap.summary_plot(shap_values, X_test_num.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CIBT43CY9Rza",
      "metadata": {
        "id": "CIBT43CY9Rza"
      },
      "source": [
        "Choose another method of your preference to explain the NN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3BMxP6m9Sij",
      "metadata": {
        "id": "a3BMxP6m9Sij"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "aRttCOde6rMA",
      "metadata": {
        "id": "aRttCOde6rMA"
      },
      "source": [
        "# BIAS for the numerical problem\n",
        "\n",
        "After having set a threshold = 0.0002 = 0.02%, define a variable called \"risk_category\" that takes values High or Low if variable \"proportion_risk_premium\" is higher or lower than the treshold.\n",
        "\n",
        "Similarly, define variable \"risk_category_pred\" that does the same but on the basis of the values predicted by the Neural Network model. For these two variables, count the number of High and Low values for Females and Males."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Catz0tFI4SXm",
      "metadata": {
        "id": "Catz0tFI4SXm"
      },
      "outputs": [],
      "source": [
        "# Threshold = 0.0002 = 0.02%\n",
        "threshold = 0.0002\n",
        "\n",
        "df_num['risk_category'] = np.where(df_num['proportion_risk_premium'] > threshold, 'High', 'Low')\n",
        "df_num['risk_category_pred'] ="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L4N1ibk-gKT_",
      "metadata": {
        "id": "L4N1ibk-gKT_"
      },
      "source": [
        "Using confusion_matrix, compare real and predicted values by counting False positives, False negatives, Trues positives, True negatives."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "S5pT4BN15p5H",
      "metadata": {
        "id": "S5pT4BN15p5H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "_iXYHCM_HsNY",
      "metadata": {
        "id": "_iXYHCM_HsNY"
      },
      "source": [
        "## Metrics to detect possible bias on predicted values\n",
        "Investigate possible bias on the basis of the metrics:\n",
        "\n",
        "\n",
        "*   Demographic Parity (no bias range: -0.1, 0.1)\n",
        "*   Equal Opportunity (no bias range: -0.1, 0.1)\n",
        "*   Average Odds (no bias range: -0.1, 0.1)\n",
        "*   Disparate Impact (no bias range: 0.8, 1.25)\n",
        "*   Theil Index (no bias range: 0, 0.15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dB_-avSf5nLM",
      "metadata": {
        "id": "dB_-avSf5nLM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "x44KYE-fPC8F",
      "metadata": {
        "id": "x44KYE-fPC8F"
      },
      "source": [
        "## Bias mitigation\n",
        "Proceed with:\n",
        "\n",
        "*   Preprocessing bias mitigation: choose the method, between reweighing and optimized preprocessing, that leads to a greater bias reduction\n",
        "*   In-processing bias mitigation:  choose the method, between Meta Fair\n",
        "*   Postprocessing bias mitigation: Reject option classification and equalized Odds\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x3S88Rug5n_r",
      "metadata": {
        "id": "x3S88Rug5n_r"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9QXy7m2U9gIh",
      "metadata": {
        "id": "9QXy7m2U9gIh"
      },
      "outputs": [],
      "source": [
        "# In-processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CRxLAFPz9i-x",
      "metadata": {
        "id": "CRxLAFPz9i-x"
      },
      "outputs": [],
      "source": [
        "# Post-Processing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mpjC2V4h9mwp",
      "metadata": {
        "id": "mpjC2V4h9mwp"
      },
      "source": [
        "Compare pros and cons of chosen methods:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "46bebee8",
      "metadata": {
        "id": "46bebee8"
      },
      "source": [
        "Write down in text what you think the pros and cons are of the methods above"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "aibe_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}